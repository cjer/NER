{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "1. Prepare corpus + decide on splits and experiment design\n",
    "1. Add multiple word embeddings to model_builder and configs\n",
    "1. Save test predictions to disk for every model\n",
    "1. Run all configs (start with CRF ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:24.034028Z",
     "start_time": "2019-03-13T07:20:22.687626Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:24.382406Z",
     "start_time": "2019-03-13T07:20:24.037019Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:27.996727Z",
     "start_time": "2019-03-13T07:20:24.385088Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:28.016424Z",
     "start_time": "2019-03-13T07:20:27.999427Z"
    }
   },
   "outputs": [],
   "source": [
    "from conlleval import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.read_csv('curation.csv.gz')\n",
    "      .assign(sent=lambda x: x.file+'_'+x.sent.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_tok_num</th>\n",
       "      <th>tok_offset</th>\n",
       "      <th>token</th>\n",
       "      <th>FEAT_gender</th>\n",
       "      <th>FEAT_number</th>\n",
       "      <th>FEAT_case</th>\n",
       "      <th>FEAT_degree</th>\n",
       "      <th>FEAT_transitivity</th>\n",
       "      <th>FEAT_tense</th>\n",
       "      <th>FEAT_mood</th>\n",
       "      <th>...</th>\n",
       "      <th>dep_flavor</th>\n",
       "      <th>dep_lex_morph_pos</th>\n",
       "      <th>dep_arc</th>\n",
       "      <th>EXTRA</th>\n",
       "      <th>sent</th>\n",
       "      <th>ner_layers</th>\n",
       "      <th>ner_type</th>\n",
       "      <th>is_ner</th>\n",
       "      <th>biose</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1</td>\n",
       "      <td>0-5</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>Fem</td>\n",
       "      <td>Plur</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>...</td>\n",
       "      <td>basic</td>\n",
       "      <td>1-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dev_1-100.tsv_1</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>dev_1-100.tsv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-2</td>\n",
       "      <td>6-11</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>Masc</td>\n",
       "      <td>Plur</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>...</td>\n",
       "      <td>basic</td>\n",
       "      <td>1-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dev_1-100.tsv_1</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>dev_1-100.tsv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-3</td>\n",
       "      <td>12-18</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>Masc</td>\n",
       "      <td>Plur</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>...</td>\n",
       "      <td>basic</td>\n",
       "      <td>1-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dev_1-100.tsv_1</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>dev_1-100.tsv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-4</td>\n",
       "      <td>19-20</td>\n",
       "      <td>מ</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>...</td>\n",
       "      <td>basic</td>\n",
       "      <td>1-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dev_1-100.tsv_1</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>dev_1-100.tsv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-5</td>\n",
       "      <td>21-27</td>\n",
       "      <td>תאילנד</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>...</td>\n",
       "      <td>basic</td>\n",
       "      <td>1-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dev_1-100.tsv_1</td>\n",
       "      <td>1</td>\n",
       "      <td>GPE</td>\n",
       "      <td>True</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>dev_1-100.tsv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sent_tok_num tok_offset   token FEAT_gender FEAT_number FEAT_case  \\\n",
       "0          1-1        0-5   עשרות         Fem        Plur         *   \n",
       "1          1-2       6-11   אנשים        Masc        Plur         *   \n",
       "2          1-3      12-18  מגיעים        Masc        Plur         *   \n",
       "3          1-4      19-20       מ           _           _         _   \n",
       "4          1-5      21-27  תאילנד           _           _         _   \n",
       "\n",
       "  FEAT_degree FEAT_transitivity FEAT_tense FEAT_mood  ... dep_flavor  \\\n",
       "0           *                 *          *         *  ...      basic   \n",
       "1           *                 *          *         *  ...      basic   \n",
       "2           *                 *          *         *  ...      basic   \n",
       "3           _                 _          _         _  ...      basic   \n",
       "4           _                 _          _         _  ...      basic   \n",
       "\n",
       "  dep_lex_morph_pos dep_arc EXTRA             sent ner_layers ner_type is_ner  \\\n",
       "0               1-2     NaN   NaN  dev_1-100.tsv_1          0        _  False   \n",
       "1               1-3     NaN   NaN  dev_1-100.tsv_1          0        _  False   \n",
       "2               1-3     NaN   NaN  dev_1-100.tsv_1          0        _  False   \n",
       "3               1-5     NaN   NaN  dev_1-100.tsv_1          0        _  False   \n",
       "4               1-3     NaN   NaN  dev_1-100.tsv_1          1      GPE   True   \n",
       "\n",
       "   biose           file  \n",
       "0      O  dev_1-100.tsv  \n",
       "1      O  dev_1-100.tsv  \n",
       "2      O  dev_1-100.tsv  \n",
       "3      O  dev_1-100.tsv  \n",
       "4  S-GPE  dev_1-100.tsv  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent_tok_num</th>\n",
       "      <td>1-1</td>\n",
       "      <td>1-2</td>\n",
       "      <td>1-3</td>\n",
       "      <td>1-4</td>\n",
       "      <td>1-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tok_offset</th>\n",
       "      <td>0-5</td>\n",
       "      <td>6-11</td>\n",
       "      <td>12-18</td>\n",
       "      <td>19-20</td>\n",
       "      <td>21-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <td>עשרות</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>מ</td>\n",
       "      <td>תאילנד</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_gender</th>\n",
       "      <td>Fem</td>\n",
       "      <td>Masc</td>\n",
       "      <td>Masc</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_number</th>\n",
       "      <td>Plur</td>\n",
       "      <td>Plur</td>\n",
       "      <td>Plur</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_case</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_degree</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_transitivity</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_tense</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_mood</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_voice</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>Act</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_definiteness</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_value</th>\n",
       "      <td>Definite=Cons\\|Gender=Fem\\|Number=Plur</td>\n",
       "      <td>Gender=Masc\\|Number=Plur</td>\n",
       "      <td>Gender=Masc\\|HebBinyan=HIFIL\\|Number=Plur\\|Per...</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_person</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>1,2,3</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_aspect</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner</th>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma</th>\n",
       "      <td>עשרות</td>\n",
       "      <td>איש</td>\n",
       "      <td>הגיע</td>\n",
       "      <td>מ</td>\n",
       "      <td>תאילנד</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_form</th>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>מתאילנד[84]</td>\n",
       "      <td>מתאילנד[84]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dep_type</th>\n",
       "      <td>nummod</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>root</td>\n",
       "      <td>case</td>\n",
       "      <td>obl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dep_flavor</th>\n",
       "      <td>basic</td>\n",
       "      <td>basic</td>\n",
       "      <td>basic</td>\n",
       "      <td>basic</td>\n",
       "      <td>basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dep_lex_morph_pos</th>\n",
       "      <td>1-2</td>\n",
       "      <td>1-3</td>\n",
       "      <td>1-3</td>\n",
       "      <td>1-5</td>\n",
       "      <td>1-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dep_arc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXTRA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent</th>\n",
       "      <td>dev_1-100.tsv_1</td>\n",
       "      <td>dev_1-100.tsv_1</td>\n",
       "      <td>dev_1-100.tsv_1</td>\n",
       "      <td>dev_1-100.tsv_1</td>\n",
       "      <td>dev_1-100.tsv_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_layers</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_type</th>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_ner</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biose</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>S-GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>dev_1-100.tsv</td>\n",
       "      <td>dev_1-100.tsv</td>\n",
       "      <td>dev_1-100.tsv</td>\n",
       "      <td>dev_1-100.tsv</td>\n",
       "      <td>dev_1-100.tsv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0  \\\n",
       "sent_tok_num                                          1-1   \n",
       "tok_offset                                            0-5   \n",
       "token                                               עשרות   \n",
       "FEAT_gender                                           Fem   \n",
       "FEAT_number                                          Plur   \n",
       "FEAT_case                                               *   \n",
       "FEAT_degree                                             *   \n",
       "FEAT_transitivity                                       *   \n",
       "FEAT_tense                                              *   \n",
       "FEAT_mood                                               *   \n",
       "FEAT_voice                                              *   \n",
       "FEAT_definiteness                                       *   \n",
       "FEAT_value         Definite=Cons\\|Gender=Fem\\|Number=Plur   \n",
       "FEAT_person                                             *   \n",
       "FEAT_aspect                                             *   \n",
       "pos                                                   NUM   \n",
       "ner                                                     _   \n",
       "lemma                                               עשרות   \n",
       "surface_form                                            _   \n",
       "dep_type                                           nummod   \n",
       "dep_flavor                                          basic   \n",
       "dep_lex_morph_pos                                     1-2   \n",
       "dep_arc                                               NaN   \n",
       "EXTRA                                                 NaN   \n",
       "sent                                      dev_1-100.tsv_1   \n",
       "ner_layers                                              0   \n",
       "ner_type                                                _   \n",
       "is_ner                                              False   \n",
       "biose                                                   O   \n",
       "file                                        dev_1-100.tsv   \n",
       "\n",
       "                                          1  \\\n",
       "sent_tok_num                            1-2   \n",
       "tok_offset                             6-11   \n",
       "token                                 אנשים   \n",
       "FEAT_gender                            Masc   \n",
       "FEAT_number                            Plur   \n",
       "FEAT_case                                 *   \n",
       "FEAT_degree                               *   \n",
       "FEAT_transitivity                         *   \n",
       "FEAT_tense                                *   \n",
       "FEAT_mood                                 *   \n",
       "FEAT_voice                                *   \n",
       "FEAT_definiteness                         *   \n",
       "FEAT_value         Gender=Masc\\|Number=Plur   \n",
       "FEAT_person                               *   \n",
       "FEAT_aspect                               *   \n",
       "pos                                    NOUN   \n",
       "ner                                       _   \n",
       "lemma                                   איש   \n",
       "surface_form                              _   \n",
       "dep_type                              nsubj   \n",
       "dep_flavor                            basic   \n",
       "dep_lex_morph_pos                       1-3   \n",
       "dep_arc                                 NaN   \n",
       "EXTRA                                   NaN   \n",
       "sent                        dev_1-100.tsv_1   \n",
       "ner_layers                                0   \n",
       "ner_type                                  _   \n",
       "is_ner                                False   \n",
       "biose                                     O   \n",
       "file                          dev_1-100.tsv   \n",
       "\n",
       "                                                                   2  \\\n",
       "sent_tok_num                                                     1-3   \n",
       "tok_offset                                                     12-18   \n",
       "token                                                         מגיעים   \n",
       "FEAT_gender                                                     Masc   \n",
       "FEAT_number                                                     Plur   \n",
       "FEAT_case                                                          *   \n",
       "FEAT_degree                                                        *   \n",
       "FEAT_transitivity                                                  *   \n",
       "FEAT_tense                                                         *   \n",
       "FEAT_mood                                                          *   \n",
       "FEAT_voice                                                       Act   \n",
       "FEAT_definiteness                                                  *   \n",
       "FEAT_value         Gender=Masc\\|HebBinyan=HIFIL\\|Number=Plur\\|Per...   \n",
       "FEAT_person                                                    1,2,3   \n",
       "FEAT_aspect                                                        *   \n",
       "pos                                                             VERB   \n",
       "ner                                                                _   \n",
       "lemma                                                           הגיע   \n",
       "surface_form                                                       _   \n",
       "dep_type                                                        root   \n",
       "dep_flavor                                                     basic   \n",
       "dep_lex_morph_pos                                                1-3   \n",
       "dep_arc                                                          NaN   \n",
       "EXTRA                                                            NaN   \n",
       "sent                                                 dev_1-100.tsv_1   \n",
       "ner_layers                                                         0   \n",
       "ner_type                                                           _   \n",
       "is_ner                                                         False   \n",
       "biose                                                              O   \n",
       "file                                                   dev_1-100.tsv   \n",
       "\n",
       "                                 3                4  \n",
       "sent_tok_num                   1-4              1-5  \n",
       "tok_offset                   19-20            21-27  \n",
       "token                            מ           תאילנד  \n",
       "FEAT_gender                      _                _  \n",
       "FEAT_number                      _                _  \n",
       "FEAT_case                        _                _  \n",
       "FEAT_degree                      _                _  \n",
       "FEAT_transitivity                _                _  \n",
       "FEAT_tense                       _                _  \n",
       "FEAT_mood                        _                _  \n",
       "FEAT_voice                       _                _  \n",
       "FEAT_definiteness                _                _  \n",
       "FEAT_value                       _                _  \n",
       "FEAT_person                      _                _  \n",
       "FEAT_aspect                      _                _  \n",
       "pos                            ADP            PROPN  \n",
       "ner                              _              GPE  \n",
       "lemma                            מ           תאילנד  \n",
       "surface_form           מתאילנד[84]      מתאילנד[84]  \n",
       "dep_type                      case              obl  \n",
       "dep_flavor                   basic            basic  \n",
       "dep_lex_morph_pos              1-5              1-3  \n",
       "dep_arc                        NaN              NaN  \n",
       "EXTRA                          NaN              NaN  \n",
       "sent               dev_1-100.tsv_1  dev_1-100.tsv_1  \n",
       "ner_layers                       0                1  \n",
       "ner_type                         _              GPE  \n",
       "is_ner                       False             True  \n",
       "biose                            O            S-GPE  \n",
       "file                 dev_1-100.tsv    dev_1-100.tsv  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent\n",
       "dev_1-100.tsv_1      [[עשרות, NUM, O], [אנשים, NOUN, O], [מגיעים, V...\n",
       "dev_1-100.tsv_10     [[ישראל, PROPN, B-PER], [ארד, PROPN, E-PER], [...\n",
       "dev_1-100.tsv_100    [[טום, PROPN, B-PER], [הארקין, PROPN, E-PER], ...\n",
       "dev_1-100.tsv_11     [[ח\"כ, NOUN, O], [אלי, PROPN, B-PER], [דיין, P...\n",
       "dev_1-100.tsv_12     [[חברות, NOUN, O], [ה, SCONJ, O], [מעסיקות, VE...\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df\n",
    "sents = x.groupby('sent')[['token', 'pos', 'biose']].apply(lambda x: x.values.tolist())\n",
    "sents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17824"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(x[\"token\"].values))\n",
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:37.811197Z",
     "start_time": "2019-03-13T07:20:37.785263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(x[\"biose\"].values))\n",
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f102e2ef3c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x.groupby('sent').size().hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:37.844108Z",
     "start_time": "2019-03-13T07:20:37.817179Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = 80\n",
    "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1\n",
    "word2idx[\"PAD\"] = 0\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "tag2idx = {t: i + 1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:47.936127Z",
     "start_time": "2019-03-13T07:20:37.850093Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:47.999954Z",
     "start_time": "2019-03-13T07:20:47.940116Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=max_len, sequences=X, value=word2idx[\"PAD\"], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:48.014918Z",
     "start_time": "2019-03-13T07:20:48.004944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13525,  5670, 10268,  4015,   814,  3870,   814,  7148, 10268,\n",
       "       11089,  4304, 12701, 17200,  5971,   814, 14247,   978,   814,\n",
       "        7060, 10268,  8339,  9834, 10268, 11769, 10450, 14549, 11491,\n",
       "       10953, 10268,  8479,  4767,   201,  9075,  3129, 17604, 17692,\n",
       "         814, 10280, 13241,  4102, 14170, 12568,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:48.041845Z",
     "start_time": "2019-03-13T07:20:48.018906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = list(set(x[\"pos\"].values))\n",
    "n_pos = len(pos); n_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:48.137589Z",
     "start_time": "2019-03-13T07:20:48.048826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  7, 11, 14,  8, 14,  8,  1, 13, 11, 14,  7,  2,  9,  3, 11,  7,\n",
       "        6,  6,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos2idx = {w: i+1 for i, w in enumerate(pos)}\n",
    "pos2idx[\"PAD\"] = 0\n",
    "X_pos = [[pos2idx[w[1]] for w in s] for s in sents]\n",
    "X_pos = pad_sequences(maxlen=max_len, sequences=X_pos, value=pos2idx[\"PAD\"], padding='post', truncating='post')\n",
    "X_pos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T15:26:01.689647Z",
     "start_time": "2019-03-12T15:26:01.684664Z"
    }
   },
   "source": [
    "## True tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:48.210396Z",
     "start_time": "2019-03-13T07:20:48.144570Z"
    }
   },
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[2]] for w in s] for s in sents]\n",
    "y_numer = pad_sequences(maxlen=max_len, sequences=y, value=tag2idx[\"PAD\"], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:48.223360Z",
     "start_time": "2019-03-13T07:20:48.213386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 30,  1,  1, 20, 11, 11, 24,  1,  1,  1,  1,  1,  1, 20, 11, 11,\n",
       "       11, 24,  1, 35, 30,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_numer[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:48.330074Z",
     "start_time": "2019-03-13T07:20:48.226353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags+1) for i in y_numer]\n",
    "y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:21:19.620040Z",
     "start_time": "2019-03-13T07:21:18.960804Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "splits = [train_test_split(X, y, X_pos, test_size=0.25, random_state=42+i) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep char input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T13:58:31.324599Z",
     "start_time": "2019-01-31T13:58:31.077207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0fd41449e8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x.token.apply(len).hist(bins=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T13:58:31.340217Z",
     "start_time": "2019-01-31T13:58:31.324599Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len_char = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T13:58:32.660554Z",
     "start_time": "2019-01-31T13:58:32.613692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "chars = set([w_i for w in words for w_i in w])\n",
    "n_chars = len(chars)\n",
    "print(n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T13:58:33.732950Z",
     "start_time": "2019-01-31T13:58:33.717366Z"
    }
   },
   "outputs": [],
   "source": [
    "char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
    "char2idx[\"UNK\"] = 1\n",
    "char2idx[\"PAD\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T13:58:36.324286Z",
     "start_time": "2019-01-31T13:58:34.303392Z"
    }
   },
   "outputs": [],
   "source": [
    "X_char = []\n",
    "for sentence in sents:\n",
    "    sent_seq = []\n",
    "    for i in range(max_len):\n",
    "        word_seq = []\n",
    "        for j in range(max_len_char):\n",
    "            try:\n",
    "                word_seq.append(char2idx.get(sentence[i][0][j]))\n",
    "            except:\n",
    "                word_seq.append(char2idx.get(\"PAD\"))\n",
    "        sent_seq.append(word_seq)\n",
    "    X_char.append(np.array(sent_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_char = [train_test_split(X_char, y, test_size=0.25, random_state=42+i) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T16:54:33.547605Z",
     "start_time": "2019-03-27T16:54:33.391216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src  wiki.he.vec\n"
     ]
    }
   ],
   "source": [
    "!ls '../fasttext/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(path, embed_dim=300, MAX_NB_WORDS=100000):\n",
    "    #load embeddings\n",
    "    print('loading word embeddings...')\n",
    "    embeddings_index = {}\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.rstrip().rsplit(' ')\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print('found %s word vectors' % len(embeddings_index))\n",
    "    #embedding matrix\n",
    "    print('preparing embedding matrix...')\n",
    "    words_not_found = []\n",
    "    nb_words = min(MAX_NB_WORDS, len(word2idx))\n",
    "    embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "    for word, i in word2idx.items():\n",
    "        if i >= nb_words:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word.strip('_'))\n",
    "        if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            words_not_found.append(word)\n",
    "    print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "    print(\"sample words not found: \", np.random.choice(words_not_found, 10))\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings...\n",
      "found 488937 word vectors\n",
      "preparing embedding matrix...\n",
      "number of null word embeddings: 1529\n",
      "sample words not found:  ['טירמיס' '13.00' 'מקסיקאיים' 'איזמירלי' '8591' 'תועסק' 'שוקחתן' '2,162'\n",
      " 'אלמולזינו' 'להתנאות']\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_ft_pt = get_embedding_matrix('../fasttext/wiki.he.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = embedding_matrix_ft_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:21:19.634004Z",
     "start_time": "2019-03-13T07:21:19.622036Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Flatten, Concatenate\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Flatten, Concatenate\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.metrics import crf_accuracy\n",
    "from keras_contrib.losses import crf_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D\n",
    "from keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histories(histories, crf=False, **kwargs):\n",
    "    for h in histories:\n",
    "        plt.figure()\n",
    "        if crf:\n",
    "            plt.plot(h[\"crf_accuracy\"])\n",
    "            plt.plot(h[\"val_crf_accuracy\"]) \n",
    "        else:   \n",
    "            plt.plot(h[\"acc\"])\n",
    "            plt.plot(h[\"val_acc\"])\n",
    "        plt.show()\n",
    "        \n",
    "def predict_test_sentence(splits, models, words, i, use_word=True, use_pos=True, use_char=False, **kwargs):\n",
    "    for split, model in zip(splits, models):\n",
    "        if use_char:\n",
    "            split, char_split = split\n",
    "            X_char_tr, X_char_te, _, _ = char_split\n",
    "        X_tr, X_te, y_tr, y_te, pos_tr, pos_te = split\n",
    "        params = []\n",
    "        if use_word:\n",
    "            params.append(np.array([X_te[i]]))\n",
    "        if use_pos:\n",
    "            params.append(np.array([pos_te[i]]))\n",
    "        if use_char:\n",
    "            params.append(np.array([X_char_te[i]]))\n",
    "        p = model.predict(params)\n",
    "        p = np.argmax(p, axis=-1)\n",
    "        t = np.argmax(y_te[i], axis=-1)\n",
    "        print(\"{:15} ({:5}): {}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "        for w, pred, tr in zip(X_te[i], p[0], t):\n",
    "            if idx2word[w]!=\"PAD\":\n",
    "                print(\"{:15} ({:5}): {}\".format(idx2word[w], idx2tag[tr], idx2tag[pred]))\n",
    "                \n",
    "def predict_on_splits(splits, models, words, use_word=True, use_pos=False, use_char=False, predict_on_train=False, **kwargs):\n",
    "    all_cat_preds = []\n",
    "    all_cat_y_te = []\n",
    "    all_words_flat = []\n",
    "    for split, model in zip(splits, models):\n",
    "        split, char_split = split\n",
    "        X_char_tr, X_char_te, _, _ = char_split\n",
    "        X_tr, X_te, y_tr, y_te, pos_tr, pos_te = split\n",
    "        \n",
    "        if predict_on_train:\n",
    "            X_te, y_te, pos_te = X_tr, y_tr, pos_tr\n",
    "        params = []\n",
    "        if use_word:\n",
    "            params.append(np.array(X_te))\n",
    "        if use_pos:\n",
    "            params.append(np.array(pos_te))\n",
    "        if use_char:\n",
    "            params.append(np.array(X_char_te))\n",
    "        preds = model.predict(params)\n",
    "        preds = np.argmax(preds, axis=-1)\n",
    "        cat_preds = []\n",
    "        cat_y_te = []\n",
    "        words_flat = []\n",
    "        y_te_num = np.argmax(y_te, axis=-1)\n",
    "        for ws, s, t in zip(X_te, preds, y_te_num):\n",
    "            for w, pred, tr in zip(ws, s, t):\n",
    "                if idx2word[w]!=\"PAD\":\n",
    "                    words_flat.append(idx2word[w])\n",
    "                    cat_preds.append(idx2tag[pred].replace('_', '-'))\n",
    "                    cat_y_te.append(idx2tag[tr].replace('_', '-'))\n",
    "\n",
    "        all_cat_preds.append(cat_preds)\n",
    "        all_cat_y_te.append(cat_y_te)\n",
    "        all_words_flat.append(words_flat)\n",
    "        \n",
    "    return (all_cat_preds, all_cat_y_te, all_words_flat)\n",
    "    \n",
    "def replace_pad_with_o(ll):\n",
    "    new_ll = ['O' if label=='PAD' else label for label in ll]\n",
    "    return new_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(words, chars, use_word=True, use_pos=False, embedding_matrix=None, \n",
    "                       embed_dim=70, trainable=True, input_dropout=False, stack_lstm=1,\n",
    "                       epochs=100, early_stopping=True, patience=20, min_delta=0.0001,\n",
    "                       use_char=False, crf=False,\n",
    "                       stack_cross=False, stack_double=False, rec_dropout=0.1,\n",
    "                       verbose=1):\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te, pos_tr, pos_te = words\n",
    "    X_char_tr, X_char_te, _, _ = chars\n",
    "    all_input_embeds = []\n",
    "    all_inputs = []\n",
    "    train_data = []\n",
    "    if use_word:\n",
    "        input = Input(shape=(max_len,))\n",
    "        if embedding_matrix is not None:\n",
    "            input_embed = Embedding(input_dim=n_words+2, output_dim=embed_dim, input_length=max_len, \n",
    "                                weights=[embedding_matrix], trainable=trainable)(input)\n",
    "        else:\n",
    "            input_embed = Embedding(input_dim=n_words+2, output_dim=embed_dim, input_length=max_len)(input)\n",
    "        all_input_embeds.append(input_embed)\n",
    "        all_inputs.append(input)\n",
    "        train_data.append(X_tr)\n",
    "    if use_pos:\n",
    "        pos_input = Input(shape=(max_len,))\n",
    "        pos_embed = Embedding(input_dim=n_pos+1, output_dim=10, input_length=max_len)(pos_input)\n",
    "        all_input_embeds.append(pos_embed)\n",
    "        all_inputs.append(pos_input)\n",
    "        train_data.append(pos_tr)\n",
    "    if use_char:\n",
    "        # input and embeddings for characters\n",
    "        char_in = Input(shape=(max_len, max_len_char,))\n",
    "        emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2, output_dim=20,\n",
    "                                   input_length=max_len_char))(char_in)\n",
    "        # character LSTM to get word encodings by characters\n",
    "        char_enc = TimeDistributed(Bidirectional(LSTM(units=10, return_sequences=False,\n",
    "                                        recurrent_dropout=0.5)))(emb_char)\n",
    "        all_input_embeds.append(char_enc)\n",
    "        all_inputs.append(char_in)\n",
    "        train_data.append(np.array(X_char_tr).reshape((len(X_char_tr), max_len, max_len_char)))\n",
    "    if len(all_inputs)>1:\n",
    "        model = Concatenate()(all_input_embeds)\n",
    "        if (use_char):\n",
    "            model = SpatialDropout1D(0.3)(model)\n",
    "    else: \n",
    "        model = all_input_embeds[0]\n",
    "        all_input_embeds = all_input_embeds[0]\n",
    "        all_inputs = all_inputs[0]\n",
    "        train_data = train_data[0]\n",
    "\n",
    "    if input_dropout:\n",
    "        model = Dropout(0.1)(model)\n",
    "\n",
    "    if stack_double:\n",
    "        front = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout)(model)\n",
    "        front = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout)(front)\n",
    "        back = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout, go_backwards=True)(model)\n",
    "        model = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout, go_backwards=True)(back)\n",
    "    if stack_cross:\n",
    "        front = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout)(model)\n",
    "        front = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout)(front)\n",
    "        back = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout, go_backwards=True)(model)\n",
    "        back = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout, go_backwards=True)(back)\n",
    "        model = concatenate([back, front])\n",
    "    for i in range(stack_lstm):\n",
    "        model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout))(model)\n",
    "\n",
    "    if crf:\n",
    "        model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "        crf = CRF(n_tags+1)\n",
    "        loss = crf_loss\n",
    "        metric = crf_accuracy\n",
    "        monitor = 'val_crf_accuracy'\n",
    "        out = crf(model)\n",
    "    else:\n",
    "        out = TimeDistributed(Dense(n_tags+1, activation=\"softmax\"))(model)  # softmax output layer\n",
    "        loss = \"categorical_crossentropy\"\n",
    "        metric = 'accuracy'\n",
    "        monitor = 'val_acc'\n",
    "\n",
    "    model = Model(all_inputs, out)\n",
    "    model.compile(optimizer=\"rmsprop\", loss=loss, metrics=[metric])\n",
    "    if early_stopping:\n",
    "        es = [EarlyStopping(monitor=monitor, mode='max', verbose=1, patience=patience, restore_best_weights=True, min_delta=min_delta)]\n",
    "    else:\n",
    "        es=None\n",
    "    history = model.fit(train_data, np.array(y_tr), batch_size=32, epochs=epochs, \n",
    "                        validation_split=0.1, verbose=verbose, callbacks=es)\n",
    "    hist = pd.DataFrame(history.history)\n",
    "        \n",
    "    return model, hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(words, chars, use_word=True, use_pos=False, embedding_matrix=None, \n",
    "                       embed_dim=70, trainable=True, input_dropout=False, stack_lstm=1,\n",
    "                       epochs=100, early_stopping=True, patience=20, min_delta=0.0001,\n",
    "                       use_char=False, crf=False, add_random_embedding=False, pretrained_embed_dim=300,\n",
    "                       stack_cross=False, stack_double=False, rec_dropout=0.1,\n",
    "                       verbose=1):\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te, pos_tr, pos_te = words\n",
    "    X_char_tr, X_char_te, _, _ = chars\n",
    "    all_input_embeds = []\n",
    "    all_inputs = []\n",
    "    train_data = []\n",
    "    if use_word and not add_random_embedding and embedding_matrix is None:\n",
    "        raise ValueError('Cannot use word without embedding')\n",
    "    if use_word:\n",
    "        input = Input(shape=(max_len,))\n",
    "        if add_random_embedding:\n",
    "            input_embed = Embedding(input_dim=n_words+2, output_dim=embed_dim, input_length=max_len)(input)\n",
    "            all_input_embeds.append(input_embed)\n",
    "        if embedding_matrix is not None:\n",
    "            input_embed = Embedding(input_dim=n_words+2, output_dim=pretrained_embed_dim, input_length=max_len, \n",
    "                                weights=[embedding_mats[embedding_matrix]], trainable=trainable)(input)\n",
    "            all_input_embeds.append(input_embed)\n",
    "        all_inputs.append(input)\n",
    "        train_data.append(X_tr)\n",
    "    if use_pos:\n",
    "        pos_input = Input(shape=(max_len,))\n",
    "        pos_embed = Embedding(input_dim=n_pos+1, output_dim=10, input_length=max_len)(pos_input)\n",
    "        all_input_embeds.append(pos_embed)\n",
    "        all_inputs.append(pos_input)\n",
    "        train_data.append(pos_tr)\n",
    "    if use_char:\n",
    "        # input and embeddings for characters\n",
    "        char_in = Input(shape=(max_len, max_len_char,))\n",
    "        emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2, output_dim=20,\n",
    "                                   input_length=max_len_char))(char_in)\n",
    "        # character LSTM to get word encodings by characters\n",
    "        char_enc = TimeDistributed(Bidirectional(LSTM(units=10, return_sequences=False,\n",
    "                                        recurrent_dropout=0.5)))(emb_char)\n",
    "        all_input_embeds.append(char_enc)\n",
    "        all_inputs.append(char_in)\n",
    "        train_data.append(np.array(X_char_tr).reshape((len(X_char_tr), max_len, max_len_char)))\n",
    "    if len(all_inputs)>1:\n",
    "        model = Concatenate()(all_input_embeds)\n",
    "        if (use_char):\n",
    "            model = SpatialDropout1D(0.3)(model)\n",
    "    else: \n",
    "        model = all_input_embeds[0]\n",
    "        all_input_embeds = all_input_embeds[0]\n",
    "        all_inputs = all_inputs[0]\n",
    "        train_data = train_data[0]\n",
    "\n",
    "    if input_dropout:\n",
    "        model = Dropout(0.1)(model)\n",
    "\n",
    "    if stack_double:\n",
    "        front = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout)(model)\n",
    "        front = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout)(front)\n",
    "        back = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout, go_backwards=True)(model)\n",
    "        model = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout, go_backwards=True)(back)\n",
    "    if stack_cross:\n",
    "        front = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout)(model)\n",
    "        front = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout)(front)\n",
    "        back = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout, go_backwards=True)(model)\n",
    "        back = LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout, go_backwards=True)(back)\n",
    "        model = concatenate([back, front])\n",
    "    for i in range(stack_lstm):\n",
    "        model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=rec_dropout))(model)\n",
    "\n",
    "    if crf:\n",
    "        model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "        crf = CRF(n_tags+1)\n",
    "        loss = crf_loss\n",
    "        metric = crf_accuracy\n",
    "        monitor = 'val_crf_accuracy'\n",
    "        out = crf(model)\n",
    "    else:\n",
    "        out = TimeDistributed(Dense(n_tags+1, activation=\"softmax\"))(model)  # softmax output layer\n",
    "        loss = \"categorical_crossentropy\"\n",
    "        metric = 'accuracy'\n",
    "        monitor = 'val_acc'\n",
    "\n",
    "    model = Model(all_inputs, out)\n",
    "    model.compile(optimizer=\"rmsprop\", loss=loss, metrics=[metric])\n",
    "    if early_stopping:\n",
    "        es = [EarlyStopping(monitor=monitor, mode='max', verbose=1, patience=patience, restore_best_weights=True, min_delta=min_delta)]\n",
    "    else:\n",
    "        es=None\n",
    "    history = model.fit(train_data, np.array(y_tr), batch_size=32, epochs=epochs, \n",
    "                        validation_split=0.1, verbose=verbose, callbacks=es)\n",
    "    hist = pd.DataFrame(history.history)\n",
    "        \n",
    "    return model, hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "preds = []\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "            #{'use_pos': False },\n",
    "            #{'use_pos': True},\n",
    "            #{'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            #{'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            #{'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            #{'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            {'crf': True, 'use_pos': False},\n",
    "            {'crf': True, 'use_pos': True},\n",
    "            #{'crf': True, 'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            {'crf': True, 'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            #{'crf': True, 'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            {'crf': True, 'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            #{'use_char': True, 'use_word': False, 'use_pos': False },\n",
    "            #{'use_char': True, 'use_word': False, 'use_pos': True},\n",
    "            #{'use_char': True, 'use_pos': False },\n",
    "            #{'use_char': True, 'use_pos': True},\n",
    "            #{'use_char': True, 'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            #{'use_char': True, 'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            #{'use_char': True, 'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            #{'use_char': True, 'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            {'use_char': True, 'crf': True, 'use_pos': False},\n",
    "            {'use_char': True, 'crf': True, 'use_pos': True},\n",
    "            #{'use_char': True, 'crf': True, 'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            {'use_char': True, 'crf': True, 'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            #{'use_char': True, 'crf': True, 'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            {'use_char': True, 'crf': True, 'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "            #{'use_pos': False },\n",
    "            #{'use_pos': True},\n",
    "            #{'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            #{'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            #{'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            #{'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            {'crf': True, 'use_pos': False},\n",
    "            {'crf': True, 'use_pos': True},\n",
    "            #{'crf': True, 'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            {'crf': True, 'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            #{'crf': True, 'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            {'crf': True, 'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            #{'use_char': True, 'use_word': False, 'use_pos': False },\n",
    "            #{'use_char': True, 'use_word': False, 'use_pos': True},\n",
    "            #{'use_char': True, 'use_pos': False },\n",
    "            #{'use_char': True, 'use_pos': True},\n",
    "            #{'use_char': True, 'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            #{'use_char': True, 'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            #{'use_char': True, 'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            #{'use_char': True, 'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            {'use_char': True, 'crf': True, 'use_pos': False},\n",
    "            {'use_char': True, 'crf': True, 'use_pos': True},\n",
    "            #{'use_char': True, 'crf': True, 'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            {'use_char': True, 'crf': True, 'use_pos': False, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "            #{'use_char': True, 'crf': True, 'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': False, 'embed_dim': embed_dim},\n",
    "            {'use_char': True, 'crf': True, 'use_pos': True, 'embedding_matrix': embedding_matrix, 'trainable': True, 'embed_dim': embed_dim},\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T11:31:02.793857Z",
     "start_time": "2019-03-13T11:16:17.267695Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4195 samples, validate on 467 samples\n",
      "Epoch 1/100\n",
      "4195/4195 [==============================] - 53s 13ms/step - loss: 0.3575 - crf_accuracy: 0.9284 - val_loss: 0.1620 - val_crf_accuracy: 0.9715\n",
      "Epoch 2/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.1367 - crf_accuracy: 0.9704 - val_loss: 0.1916 - val_crf_accuracy: 0.9621\n",
      "Epoch 3/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: 0.0997 - crf_accuracy: 0.9735 - val_loss: 0.1016 - val_crf_accuracy: 0.9754\n",
      "Epoch 4/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: 0.0723 - crf_accuracy: 0.9787 - val_loss: 0.0798 - val_crf_accuracy: 0.9799\n",
      "Epoch 5/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0519 - crf_accuracy: 0.9833 - val_loss: 0.0789 - val_crf_accuracy: 0.9719\n",
      "Epoch 6/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0378 - crf_accuracy: 0.9857 - val_loss: 0.0583 - val_crf_accuracy: 0.9804\n",
      "Epoch 7/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: 0.0268 - crf_accuracy: 0.9884 - val_loss: 0.0572 - val_crf_accuracy: 0.9822\n",
      "Epoch 8/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: 0.0179 - crf_accuracy: 0.9902 - val_loss: 0.0470 - val_crf_accuracy: 0.9837\n",
      "Epoch 9/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: 0.0103 - crf_accuracy: 0.9920 - val_loss: 0.0538 - val_crf_accuracy: 0.9776\n",
      "Epoch 10/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0042 - crf_accuracy: 0.9932 - val_loss: 0.0385 - val_crf_accuracy: 0.9833\n",
      "Epoch 11/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0013 - crf_accuracy: 0.9943 - val_loss: 0.0409 - val_crf_accuracy: 0.9803\n",
      "Epoch 12/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0058 - crf_accuracy: 0.9950 - val_loss: 0.0393 - val_crf_accuracy: 0.9821\n",
      "Epoch 13/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0098 - crf_accuracy: 0.9957 - val_loss: 0.0338 - val_crf_accuracy: 0.9825\n",
      "Epoch 14/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0135 - crf_accuracy: 0.9964 - val_loss: 0.0414 - val_crf_accuracy: 0.9829\n",
      "Epoch 15/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0165 - crf_accuracy: 0.9968 - val_loss: 0.0377 - val_crf_accuracy: 0.9832\n",
      "Epoch 16/100\n",
      "4195/4195 [==============================] - 45s 11ms/step - loss: -0.0194 - crf_accuracy: 0.9974 - val_loss: 0.0412 - val_crf_accuracy: 0.9819\n",
      "Epoch 17/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0219 - crf_accuracy: 0.9977 - val_loss: 0.0387 - val_crf_accuracy: 0.9787\n",
      "Epoch 18/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0244 - crf_accuracy: 0.9982 - val_loss: 0.0377 - val_crf_accuracy: 0.9794\n",
      "Epoch 19/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0268 - crf_accuracy: 0.9984 - val_loss: 0.0398 - val_crf_accuracy: 0.9799\n",
      "Epoch 20/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0289 - crf_accuracy: 0.9986 - val_loss: 0.0479 - val_crf_accuracy: 0.9770\n",
      "Epoch 21/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0313 - crf_accuracy: 0.9989 - val_loss: 0.0461 - val_crf_accuracy: 0.9792\n",
      "Epoch 22/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0330 - crf_accuracy: 0.9989 - val_loss: 0.0469 - val_crf_accuracy: 0.9753\n",
      "Epoch 23/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0352 - crf_accuracy: 0.9992 - val_loss: 0.0588 - val_crf_accuracy: 0.9689\n",
      "Epoch 24/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0370 - crf_accuracy: 0.9992 - val_loss: 0.0423 - val_crf_accuracy: 0.9789\n",
      "Epoch 25/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0390 - crf_accuracy: 0.9995 - val_loss: 0.0440 - val_crf_accuracy: 0.9789\n",
      "Epoch 26/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0409 - crf_accuracy: 0.9996 - val_loss: 0.0484 - val_crf_accuracy: 0.9795\n",
      "Epoch 27/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0427 - crf_accuracy: 0.9996 - val_loss: 0.0645 - val_crf_accuracy: 0.9712\n",
      "Epoch 28/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0443 - crf_accuracy: 0.9995 - val_loss: 0.0457 - val_crf_accuracy: 0.9768\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00028: early stopping\n",
      "Train on 4195 samples, validate on 467 samples\n",
      "Epoch 1/100\n",
      "4195/4195 [==============================] - 49s 12ms/step - loss: 0.3754 - crf_accuracy: 0.9160 - val_loss: 0.1899 - val_crf_accuracy: 0.9682\n",
      "Epoch 2/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.1444 - crf_accuracy: 0.9705 - val_loss: 0.1255 - val_crf_accuracy: 0.9698\n",
      "Epoch 3/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0988 - crf_accuracy: 0.9740 - val_loss: 0.0981 - val_crf_accuracy: 0.9724\n",
      "Epoch 4/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0698 - crf_accuracy: 0.9789 - val_loss: 0.0784 - val_crf_accuracy: 0.9763\n",
      "Epoch 5/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0505 - crf_accuracy: 0.9835 - val_loss: 0.0626 - val_crf_accuracy: 0.9791\n",
      "Epoch 6/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0369 - crf_accuracy: 0.9863 - val_loss: 0.0520 - val_crf_accuracy: 0.9815\n",
      "Epoch 7/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: 0.0257 - crf_accuracy: 0.9888 - val_loss: 0.0494 - val_crf_accuracy: 0.9821\n",
      "Epoch 8/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0170 - crf_accuracy: 0.9907 - val_loss: 0.0667 - val_crf_accuracy: 0.9710\n",
      "Epoch 9/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0102 - crf_accuracy: 0.9918 - val_loss: 0.0399 - val_crf_accuracy: 0.9839\n",
      "Epoch 10/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0043 - crf_accuracy: 0.9928 - val_loss: 0.0344 - val_crf_accuracy: 0.9828\n",
      "Epoch 11/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -8.1090e-04 - crf_accuracy: 0.9940 - val_loss: 0.0377 - val_crf_accuracy: 0.9794\n",
      "Epoch 12/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0054 - crf_accuracy: 0.9949 - val_loss: 0.0350 - val_crf_accuracy: 0.9842\n",
      "Epoch 13/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0092 - crf_accuracy: 0.9955 - val_loss: 0.0326 - val_crf_accuracy: 0.9820\n",
      "Epoch 14/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0129 - crf_accuracy: 0.9963 - val_loss: 0.0315 - val_crf_accuracy: 0.9825\n",
      "Epoch 15/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0161 - crf_accuracy: 0.9971 - val_loss: 0.0310 - val_crf_accuracy: 0.9834\n",
      "Epoch 16/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0190 - crf_accuracy: 0.9976 - val_loss: 0.0313 - val_crf_accuracy: 0.9813\n",
      "Epoch 17/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0217 - crf_accuracy: 0.9979 - val_loss: 0.0399 - val_crf_accuracy: 0.9789\n",
      "Epoch 18/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0241 - crf_accuracy: 0.9983 - val_loss: 0.0424 - val_crf_accuracy: 0.9801\n",
      "Epoch 19/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0264 - crf_accuracy: 0.9985 - val_loss: 0.0381 - val_crf_accuracy: 0.9791\n",
      "Epoch 20/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0287 - crf_accuracy: 0.9987 - val_loss: 0.0338 - val_crf_accuracy: 0.9826\n",
      "Epoch 21/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0308 - crf_accuracy: 0.9990 - val_loss: 0.0330 - val_crf_accuracy: 0.9806\n",
      "Epoch 22/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0327 - crf_accuracy: 0.9990 - val_loss: 0.0392 - val_crf_accuracy: 0.9816\n",
      "Epoch 23/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0348 - crf_accuracy: 0.9993 - val_loss: 0.0357 - val_crf_accuracy: 0.9777\n",
      "Epoch 24/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0367 - crf_accuracy: 0.9994 - val_loss: 0.0388 - val_crf_accuracy: 0.9773\n",
      "Epoch 25/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0387 - crf_accuracy: 0.9996 - val_loss: 0.0380 - val_crf_accuracy: 0.9788\n",
      "Epoch 26/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0405 - crf_accuracy: 0.9996 - val_loss: 0.0398 - val_crf_accuracy: 0.9797\n",
      "Epoch 27/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0422 - crf_accuracy: 0.9996 - val_loss: 0.0460 - val_crf_accuracy: 0.9782\n",
      "Epoch 28/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0440 - crf_accuracy: 0.9997 - val_loss: 0.0354 - val_crf_accuracy: 0.9798\n",
      "Epoch 29/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0458 - crf_accuracy: 0.9997 - val_loss: 0.0402 - val_crf_accuracy: 0.9807\n",
      "Epoch 30/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0475 - crf_accuracy: 0.9997 - val_loss: 0.0439 - val_crf_accuracy: 0.9775\n",
      "Epoch 31/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0493 - crf_accuracy: 0.9998 - val_loss: 0.0397 - val_crf_accuracy: 0.9797\n",
      "Epoch 32/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0510 - crf_accuracy: 0.9999 - val_loss: 0.0454 - val_crf_accuracy: 0.9769\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00032: early stopping\n",
      "Train on 4195 samples, validate on 467 samples\n",
      "Epoch 1/100\n",
      "4195/4195 [==============================] - 50s 12ms/step - loss: 0.3616 - crf_accuracy: 0.9302 - val_loss: 0.1720 - val_crf_accuracy: 0.9708\n",
      "Epoch 2/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: 0.1417 - crf_accuracy: 0.9709 - val_loss: 0.1290 - val_crf_accuracy: 0.9722\n",
      "Epoch 3/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.1013 - crf_accuracy: 0.9742 - val_loss: 0.1009 - val_crf_accuracy: 0.9736\n",
      "Epoch 4/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0736 - crf_accuracy: 0.9789 - val_loss: 0.0782 - val_crf_accuracy: 0.9775\n",
      "Epoch 5/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0522 - crf_accuracy: 0.9836 - val_loss: 0.0646 - val_crf_accuracy: 0.9796\n",
      "Epoch 6/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0382 - crf_accuracy: 0.9868 - val_loss: 0.0537 - val_crf_accuracy: 0.9816\n",
      "Epoch 7/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: 0.0282 - crf_accuracy: 0.9888 - val_loss: 0.0521 - val_crf_accuracy: 0.9818\n",
      "Epoch 8/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0201 - crf_accuracy: 0.9904 - val_loss: 0.0460 - val_crf_accuracy: 0.9825\n",
      "Epoch 9/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0132 - crf_accuracy: 0.9916 - val_loss: 0.0412 - val_crf_accuracy: 0.9834\n",
      "Epoch 10/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0075 - crf_accuracy: 0.9927 - val_loss: 0.0386 - val_crf_accuracy: 0.9825\n",
      "Epoch 11/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0020 - crf_accuracy: 0.9936 - val_loss: 0.0357 - val_crf_accuracy: 0.9820\n",
      "Epoch 12/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0027 - crf_accuracy: 0.9945 - val_loss: 0.0378 - val_crf_accuracy: 0.9815\n",
      "Epoch 13/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0067 - crf_accuracy: 0.9955 - val_loss: 0.0365 - val_crf_accuracy: 0.9811\n",
      "Epoch 14/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0105 - crf_accuracy: 0.9963 - val_loss: 0.0485 - val_crf_accuracy: 0.9732\n",
      "Epoch 15/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0136 - crf_accuracy: 0.9969 - val_loss: 0.0348 - val_crf_accuracy: 0.9811\n",
      "Epoch 16/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0166 - crf_accuracy: 0.9975 - val_loss: 0.0360 - val_crf_accuracy: 0.9797\n",
      "Epoch 17/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0193 - crf_accuracy: 0.9979 - val_loss: 0.0457 - val_crf_accuracy: 0.9699\n",
      "Epoch 18/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0218 - crf_accuracy: 0.9982 - val_loss: 0.0335 - val_crf_accuracy: 0.9809\n",
      "Epoch 19/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0242 - crf_accuracy: 0.9986 - val_loss: 0.0607 - val_crf_accuracy: 0.9692\n",
      "Epoch 20/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0264 - crf_accuracy: 0.9988 - val_loss: 0.0444 - val_crf_accuracy: 0.9767\n",
      "Epoch 21/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0285 - crf_accuracy: 0.9989 - val_loss: 0.0342 - val_crf_accuracy: 0.9785\n",
      "Epoch 22/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0307 - crf_accuracy: 0.9991 - val_loss: 0.0355 - val_crf_accuracy: 0.9808\n",
      "Epoch 23/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0327 - crf_accuracy: 0.9993 - val_loss: 0.0364 - val_crf_accuracy: 0.9801\n",
      "Epoch 24/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0346 - crf_accuracy: 0.9994 - val_loss: 0.0422 - val_crf_accuracy: 0.9787\n",
      "Epoch 25/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0365 - crf_accuracy: 0.9994 - val_loss: 0.0438 - val_crf_accuracy: 0.9767\n",
      "Epoch 26/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0383 - crf_accuracy: 0.9995 - val_loss: 0.0415 - val_crf_accuracy: 0.9776\n",
      "Epoch 27/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0401 - crf_accuracy: 0.9996 - val_loss: 0.0413 - val_crf_accuracy: 0.9763\n",
      "Epoch 28/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0419 - crf_accuracy: 0.9997 - val_loss: 0.0426 - val_crf_accuracy: 0.9796\n",
      "Epoch 29/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0437 - crf_accuracy: 0.9997 - val_loss: 0.0469 - val_crf_accuracy: 0.9760\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00029: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 39438 tokens with 1894 phrases; found: 1629 phrases; correct: 1085.\n",
      "accuracy:  54.08%; (non-O)\n",
      "accuracy:  94.77%; precision:  66.61%; recall:  57.29%; FB1:  61.60\n",
      "              ANG: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "              DUC: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "              EVE: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "              FAC: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "              GPE: precision:  81.36%; recall:  71.43%; FB1:  76.07  381\n",
      "              LOC: precision:  31.82%; recall:  16.67%; FB1:  21.87  44\n",
      "              ORG: precision:  53.83%; recall:  54.96%; FB1:  54.39  587\n",
      "              PER: precision:  72.12%; recall:  65.73%; FB1:  68.78  617\n",
      "              WOA: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "processed 40573 tokens with 1907 phrases; found: 1735 phrases; correct: 1175.\n",
      "accuracy:  55.53%; (non-O)\n",
      "accuracy:  95.01%; precision:  67.72%; recall:  61.62%; FB1:  64.52\n",
      "              ANG: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "              DUC: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "              EVE: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
      "              FAC: precision:   4.00%; recall:   2.17%; FB1:   2.82  25\n",
      "              GPE: precision:  78.40%; recall:  76.00%; FB1:  77.18  412\n",
      "              LOC: precision:  53.33%; recall:  58.33%; FB1:  55.72  105\n",
      "              ORG: precision:  67.62%; recall:  54.31%; FB1:  60.24  522\n",
      "              PER: precision:  66.07%; recall:  70.38%; FB1:  68.16  669\n",
      "              WOA: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
      "processed 40517 tokens with 1985 phrases; found: 1850 phrases; correct: 1226.\n",
      "accuracy:  59.69%; (non-O)\n",
      "accuracy:  95.12%; precision:  66.27%; recall:  61.76%; FB1:  63.94\n",
      "              ANG: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "              DUC: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "              EVE: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "              FAC: precision:   0.00%; recall:   0.00%; FB1:   0.00  3\n",
      "              GPE: precision:  83.09%; recall:  81.13%; FB1:  82.10  414\n",
      "              LOC: precision:  62.50%; recall:  39.22%; FB1:  48.19  64\n",
      "              ORG: precision:  60.10%; recall:  55.89%; FB1:  57.92  584\n",
      "              PER: precision:  62.55%; recall:  68.58%; FB1:  65.42  785\n",
      "              WOA: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "Train on 4195 samples, validate on 467 samples\n",
      "Epoch 1/100\n",
      "4195/4195 [==============================] - 50s 12ms/step - loss: 0.3497 - crf_accuracy: 0.9298 - val_loss: 0.1545 - val_crf_accuracy: 0.9717\n",
      "Epoch 2/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.1168 - crf_accuracy: 0.9722 - val_loss: 0.0910 - val_crf_accuracy: 0.9774\n",
      "Epoch 3/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0764 - crf_accuracy: 0.9800 - val_loss: 0.0667 - val_crf_accuracy: 0.9823\n",
      "Epoch 4/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0530 - crf_accuracy: 0.9832 - val_loss: 0.0565 - val_crf_accuracy: 0.9835\n",
      "Epoch 5/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0387 - crf_accuracy: 0.9862 - val_loss: 0.0459 - val_crf_accuracy: 0.9850\n",
      "Epoch 6/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0278 - crf_accuracy: 0.9888 - val_loss: 0.0421 - val_crf_accuracy: 0.9841\n",
      "Epoch 7/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0189 - crf_accuracy: 0.9908 - val_loss: 0.0354 - val_crf_accuracy: 0.9865\n",
      "Epoch 8/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: 0.0116 - crf_accuracy: 0.9922 - val_loss: 0.0369 - val_crf_accuracy: 0.9847\n",
      "Epoch 9/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0055 - crf_accuracy: 0.9933 - val_loss: 0.0293 - val_crf_accuracy: 0.9876\n",
      "Epoch 10/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 2.5277e-04 - crf_accuracy: 0.9944 - val_loss: 0.0282 - val_crf_accuracy: 0.9851\n",
      "Epoch 11/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0045 - crf_accuracy: 0.9954 - val_loss: 0.0266 - val_crf_accuracy: 0.9867\n",
      "Epoch 12/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0086 - crf_accuracy: 0.9964 - val_loss: 0.0307 - val_crf_accuracy: 0.9872\n",
      "Epoch 13/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0119 - crf_accuracy: 0.9970 - val_loss: 0.0286 - val_crf_accuracy: 0.9865\n",
      "Epoch 14/100\n",
      "4195/4195 [==============================] - 45s 11ms/step - loss: -0.0150 - crf_accuracy: 0.9977 - val_loss: 0.0303 - val_crf_accuracy: 0.9858\n",
      "Epoch 15/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0179 - crf_accuracy: 0.9980 - val_loss: 0.0407 - val_crf_accuracy: 0.9772\n",
      "Epoch 16/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0204 - crf_accuracy: 0.9984 - val_loss: 0.0259 - val_crf_accuracy: 0.9859\n",
      "Epoch 17/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0228 - crf_accuracy: 0.9988 - val_loss: 0.0255 - val_crf_accuracy: 0.9846\n",
      "Epoch 18/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0250 - crf_accuracy: 0.9990 - val_loss: 0.0271 - val_crf_accuracy: 0.9863\n",
      "Epoch 19/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0272 - crf_accuracy: 0.9992 - val_loss: 0.0361 - val_crf_accuracy: 0.9863\n",
      "Epoch 20/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0292 - crf_accuracy: 0.9993 - val_loss: 0.0295 - val_crf_accuracy: 0.9849\n",
      "Epoch 21/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0312 - crf_accuracy: 0.9996 - val_loss: 0.0309 - val_crf_accuracy: 0.9847\n",
      "Epoch 22/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0331 - crf_accuracy: 0.9996 - val_loss: 0.0291 - val_crf_accuracy: 0.9830\n",
      "Epoch 23/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0350 - crf_accuracy: 0.9997 - val_loss: 0.0339 - val_crf_accuracy: 0.9825\n",
      "Epoch 24/100\n",
      "4195/4195 [==============================] - 45s 11ms/step - loss: -0.0367 - crf_accuracy: 0.9997 - val_loss: 0.0384 - val_crf_accuracy: 0.9812\n",
      "Epoch 25/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0385 - crf_accuracy: 0.9998 - val_loss: 0.0362 - val_crf_accuracy: 0.9827\n",
      "Epoch 26/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0402 - crf_accuracy: 0.9998 - val_loss: 0.0343 - val_crf_accuracy: 0.9852\n",
      "Epoch 27/100\n",
      "4195/4195 [==============================] - 45s 11ms/step - loss: -0.0420 - crf_accuracy: 0.9999 - val_loss: 0.0319 - val_crf_accuracy: 0.9851\n",
      "Epoch 28/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0437 - crf_accuracy: 0.9999 - val_loss: 0.0356 - val_crf_accuracy: 0.9838\n",
      "Epoch 29/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0454 - crf_accuracy: 0.9999 - val_loss: 0.0455 - val_crf_accuracy: 0.9790\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00029: early stopping\n",
      "Train on 4195 samples, validate on 467 samples\n",
      "Epoch 1/100\n",
      "4195/4195 [==============================] - 50s 12ms/step - loss: 0.3520 - crf_accuracy: 0.9227 - val_loss: 0.1708 - val_crf_accuracy: 0.9675\n",
      "Epoch 2/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.1121 - crf_accuracy: 0.9724 - val_loss: 0.0917 - val_crf_accuracy: 0.9739\n",
      "Epoch 3/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0724 - crf_accuracy: 0.9802 - val_loss: 0.0672 - val_crf_accuracy: 0.9789\n",
      "Epoch 4/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0491 - crf_accuracy: 0.9839 - val_loss: 0.0520 - val_crf_accuracy: 0.9804\n",
      "Epoch 5/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: 0.0337 - crf_accuracy: 0.9866 - val_loss: 0.0428 - val_crf_accuracy: 0.9821\n",
      "Epoch 6/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0227 - crf_accuracy: 0.9892 - val_loss: 0.0353 - val_crf_accuracy: 0.9854\n",
      "Epoch 7/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0143 - crf_accuracy: 0.9910 - val_loss: 0.0263 - val_crf_accuracy: 0.9865\n",
      "Epoch 8/100\n",
      "4195/4195 [==============================] - 45s 11ms/step - loss: 0.0076 - crf_accuracy: 0.9923 - val_loss: 0.0252 - val_crf_accuracy: 0.9853\n",
      "Epoch 9/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0017 - crf_accuracy: 0.9935 - val_loss: 0.0223 - val_crf_accuracy: 0.9864\n",
      "Epoch 10/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0028 - crf_accuracy: 0.9945 - val_loss: 0.0217 - val_crf_accuracy: 0.9872\n",
      "Epoch 11/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0072 - crf_accuracy: 0.9954 - val_loss: 0.0188 - val_crf_accuracy: 0.9873\n",
      "Epoch 12/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0108 - crf_accuracy: 0.9961 - val_loss: 0.0160 - val_crf_accuracy: 0.9869\n",
      "Epoch 13/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0143 - crf_accuracy: 0.9968 - val_loss: 0.0171 - val_crf_accuracy: 0.9873\n",
      "Epoch 14/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0174 - crf_accuracy: 0.9974 - val_loss: 0.0156 - val_crf_accuracy: 0.9866\n",
      "Epoch 15/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0203 - crf_accuracy: 0.9978 - val_loss: 0.0346 - val_crf_accuracy: 0.9840\n",
      "Epoch 16/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0227 - crf_accuracy: 0.9982 - val_loss: 0.0138 - val_crf_accuracy: 0.9855\n",
      "Epoch 17/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0251 - crf_accuracy: 0.9984 - val_loss: 0.0368 - val_crf_accuracy: 0.9752\n",
      "Epoch 18/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0274 - crf_accuracy: 0.9986 - val_loss: 0.0151 - val_crf_accuracy: 0.9860\n",
      "Epoch 19/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0296 - crf_accuracy: 0.9990 - val_loss: 0.0107 - val_crf_accuracy: 0.9855\n",
      "Epoch 20/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0316 - crf_accuracy: 0.9990 - val_loss: 0.0149 - val_crf_accuracy: 0.9850\n",
      "Epoch 21/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0336 - crf_accuracy: 0.9992 - val_loss: 0.0121 - val_crf_accuracy: 0.9861\n",
      "Epoch 22/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0356 - crf_accuracy: 0.9994 - val_loss: 0.0144 - val_crf_accuracy: 0.9859\n",
      "Epoch 23/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0376 - crf_accuracy: 0.9995 - val_loss: 0.0117 - val_crf_accuracy: 0.9848\n",
      "Epoch 24/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0394 - crf_accuracy: 0.9996 - val_loss: 0.0105 - val_crf_accuracy: 0.9868\n",
      "Epoch 25/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0413 - crf_accuracy: 0.9997 - val_loss: 0.0150 - val_crf_accuracy: 0.9857\n",
      "Epoch 26/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0430 - crf_accuracy: 0.9996 - val_loss: 0.0118 - val_crf_accuracy: 0.9851\n",
      "Epoch 27/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0448 - crf_accuracy: 0.9997 - val_loss: 0.0154 - val_crf_accuracy: 0.9862\n",
      "Epoch 28/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0465 - crf_accuracy: 0.9998 - val_loss: 0.0129 - val_crf_accuracy: 0.9842\n",
      "Epoch 29/100\n",
      "4195/4195 [==============================] - 49s 12ms/step - loss: -0.0483 - crf_accuracy: 0.9998 - val_loss: 0.0159 - val_crf_accuracy: 0.9822\n",
      "Epoch 30/100\n",
      "4195/4195 [==============================] - 47s 11ms/step - loss: -0.0500 - crf_accuracy: 0.9999 - val_loss: 0.0156 - val_crf_accuracy: 0.9844\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00030: early stopping\n",
      "Train on 4195 samples, validate on 467 samples\n",
      "Epoch 1/100\n",
      "4195/4195 [==============================] - 50s 12ms/step - loss: 0.3734 - crf_accuracy: 0.9227 - val_loss: 0.1645 - val_crf_accuracy: 0.9707\n",
      "Epoch 2/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.1225 - crf_accuracy: 0.9722 - val_loss: 0.1285 - val_crf_accuracy: 0.9665\n",
      "Epoch 3/100\n",
      "4195/4195 [==============================] - 45s 11ms/step - loss: 0.0802 - crf_accuracy: 0.9797 - val_loss: 0.0724 - val_crf_accuracy: 0.9811\n",
      "Epoch 4/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0562 - crf_accuracy: 0.9835 - val_loss: 0.0582 - val_crf_accuracy: 0.9824\n",
      "Epoch 5/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0405 - crf_accuracy: 0.9861 - val_loss: 0.0475 - val_crf_accuracy: 0.9833\n",
      "Epoch 6/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0291 - crf_accuracy: 0.9884 - val_loss: 0.0369 - val_crf_accuracy: 0.9855\n",
      "Epoch 7/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0204 - crf_accuracy: 0.9903 - val_loss: 0.0348 - val_crf_accuracy: 0.9853\n",
      "Epoch 8/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0130 - crf_accuracy: 0.9918 - val_loss: 0.0308 - val_crf_accuracy: 0.9870\n",
      "Epoch 9/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0068 - crf_accuracy: 0.9930 - val_loss: 0.0305 - val_crf_accuracy: 0.9865\n",
      "Epoch 10/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: 0.0013 - crf_accuracy: 0.9941 - val_loss: 0.0259 - val_crf_accuracy: 0.9857\n",
      "Epoch 11/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0032 - crf_accuracy: 0.9949 - val_loss: 0.0346 - val_crf_accuracy: 0.9784\n",
      "Epoch 12/100\n",
      "4195/4195 [==============================] - 45s 11ms/step - loss: -0.0072 - crf_accuracy: 0.9958 - val_loss: 0.0329 - val_crf_accuracy: 0.9791\n",
      "Epoch 13/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0108 - crf_accuracy: 0.9965 - val_loss: 0.0262 - val_crf_accuracy: 0.9817\n",
      "Epoch 14/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0141 - crf_accuracy: 0.9973 - val_loss: 0.0189 - val_crf_accuracy: 0.9878\n",
      "Epoch 15/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0168 - crf_accuracy: 0.9976 - val_loss: 0.0191 - val_crf_accuracy: 0.9877\n",
      "Epoch 16/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0199 - crf_accuracy: 0.9982 - val_loss: 0.0192 - val_crf_accuracy: 0.9869\n",
      "Epoch 17/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0220 - crf_accuracy: 0.9984 - val_loss: 0.0262 - val_crf_accuracy: 0.9823\n",
      "Epoch 18/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0246 - crf_accuracy: 0.9986 - val_loss: 0.0169 - val_crf_accuracy: 0.9865\n",
      "Epoch 19/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0267 - crf_accuracy: 0.9988 - val_loss: 0.0174 - val_crf_accuracy: 0.9858\n",
      "Epoch 20/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0289 - crf_accuracy: 0.9991 - val_loss: 0.0251 - val_crf_accuracy: 0.9806\n",
      "Epoch 21/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0310 - crf_accuracy: 0.9992 - val_loss: 0.0160 - val_crf_accuracy: 0.9853\n",
      "Epoch 22/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0330 - crf_accuracy: 0.9994 - val_loss: 0.0171 - val_crf_accuracy: 0.9851\n",
      "Epoch 23/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0348 - crf_accuracy: 0.9994 - val_loss: 0.0192 - val_crf_accuracy: 0.9843\n",
      "Epoch 24/100\n",
      "4195/4195 [==============================] - 46s 11ms/step - loss: -0.0367 - crf_accuracy: 0.9995 - val_loss: 0.0165 - val_crf_accuracy: 0.9850\n",
      "Epoch 25/100\n",
      "1760/4195 [===========>..................] - ETA: 25s - loss: -0.0381 - crf_accuracy: 0.9997"
     ]
    }
   ],
   "source": [
    "for conf in configs:\n",
    "    mh = [create_model(split, char, **conf) for split, char in zip(splits, splits_char)]\n",
    "    hists = [h for m, h in mh]\n",
    "    models = [m for m, h in mh]\n",
    "    plot_histories(hists, **conf)\n",
    "    all_cat_preds, all_cat_y_te, all_words_flat = predict_on_splits(zip(splits, splits_char), models, words, **conf)\n",
    "    all_cat_preds = [replace_pad_with_o(ll) for ll in all_cat_preds]\n",
    "    res = []\n",
    "    for cat_y_te, cat_preds in zip(all_cat_y_te, all_cat_preds):\n",
    "        res.append(evaluate(cat_y_te, cat_preds))\n",
    "    results.append(res)\n",
    "    preds.append(all_cat_preds)\n",
    "    histories .append(hists)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(66.60527931246163, 57.28616684266103, 61.595231336928755),\n",
       "  (67.72334293948127, 61.61510225485055, 64.52498627127952),\n",
       "  (66.27027027027027, 61.7632241813602, 63.93741851368971)],\n",
       " [(73.11243889190658, 71.06652587117213, 72.07496653279786),\n",
       "  (74.6727376209448, 68.79916098584164, 71.61572052401746),\n",
       "  (72.9381443298969, 71.28463476070529, 72.10191082802548)],\n",
       " [(77.7602523659306, 78.08870116156284, 77.9241306638567),\n",
       "  (76.30753138075313, 76.50760356581017, 76.40743650170201),\n",
       "  (81.04683195592285, 74.1057934508816, 77.42105263157893)],\n",
       " [(81.0481736368449, 80.83421330517423, 80.94105207507269),\n",
       "  (80.71772897696839, 79.02464604090194, 79.8622151563328),\n",
       "  (80.66496163682865, 79.44584382871537, 80.0507614213198)],\n",
       " [(80.94905792044662, 61.246040126715954, 69.73249173429517),\n",
       "  (72.96969696969697, 63.13581541688515, 67.69749789148159),\n",
       "  (70.72921978582356, 69.87405541561714, 70.29903699949315)],\n",
       " [(75.57702630166399, 74.34002111932418, 74.95342028214),\n",
       "  (73.40534979423869, 74.82957524908232, 74.1106206180213),\n",
       "  (77.78364116094987, 74.25692695214106, 75.97938144329896)],\n",
       " [(83.2164058283864, 81.41499472016895, 82.30584467574059),\n",
       "  (80.12422360248446, 81.1746198217095, 80.646001562907),\n",
       "  (83.34179786693753, 82.67002518891687, 83.00455235204855)],\n",
       " [(84.09689310163245, 84.31890179514255, 84.2077511204851),\n",
       "  (83.13577586206897, 80.91242789722077, 82.00903534414032),\n",
       "  (84.26966292134831, 83.12342569269522, 83.69261983261477)]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in configs:\n",
    "    if 'embedding_matrix' in c:\n",
    "        c.update({'embedding_matrix': 'fastext'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = {'use_word': True, 'use_pos': False, 'embedding_matrix': None, \n",
    "            'embed_dim': 70, 'trainable': True, 'input_dropout': False, \n",
    "            'stack_lstm': 1, 'epochs': 100, 'early_stopping': True, 'patience': 20, \n",
    "            'min_delta': 0.0001, 'use_char': False, 'crf': False, 'stack_cross': False, \n",
    "            'stack_double': False, 'rec_dropout': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conf in configs:\n",
    "    conf.update({'use_morpheme': True})\n",
    "    conf.update({'use_word': False})\n",
    "\n",
    "    for key in defaults:\n",
    "        if key not in conf:\n",
    "            conf[key] = defaults[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'crf': True,\n",
       "   'use_pos': False,\n",
       "   'use_morpheme': True,\n",
       "   'use_word': False,\n",
       "   'embedding_matrix': None,\n",
       "   'embed_dim': 70,\n",
       "   'trainable': True,\n",
       "   'input_dropout': False,\n",
       "   'stack_lstm': 1,\n",
       "   'epochs': 100,\n",
       "   'early_stopping': True,\n",
       "   'patience': 20,\n",
       "   'min_delta': 0.0001,\n",
       "   'use_char': False,\n",
       "   'stack_cross': False,\n",
       "   'stack_double': False,\n",
       "   'rec_dropout': 0.1},\n",
       "  [(66.60527931246163, 57.28616684266103, 61.595231336928755),\n",
       "   (67.72334293948127, 61.61510225485055, 64.52498627127952),\n",
       "   (66.27027027027027, 61.7632241813602, 63.93741851368971)],\n",
       "  [    val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.162016          0.971520  0.357525      0.928409\n",
       "   1   0.191645          0.962072  0.136715      0.970420\n",
       "   2   0.101569          0.975375  0.099683      0.973489\n",
       "   3   0.079794          0.979872  0.072350      0.978692\n",
       "   4   0.078906          0.971895  0.051881      0.983287\n",
       "   5   0.058325          0.980380  0.037783      0.985724\n",
       "   6   0.057175          0.982227  0.026804      0.988361\n",
       "   7   0.047032          0.983699  0.017882      0.990238\n",
       "   8   0.053780          0.977570  0.010266      0.991952\n",
       "   9   0.038533          0.983324  0.004223      0.993200\n",
       "   10  0.040902          0.980327 -0.001299      0.994258\n",
       "   11  0.039271          0.982066 -0.005795      0.995000\n",
       "   12  0.033819          0.982521 -0.009801      0.995733\n",
       "   13  0.041361          0.982869 -0.013537      0.996389\n",
       "   14  0.037655          0.983164 -0.016548      0.996824\n",
       "   15  0.041165          0.981879 -0.019397      0.997399\n",
       "   16  0.038707          0.978694 -0.021881      0.997676\n",
       "   17  0.037746          0.979390 -0.024443      0.998197\n",
       "   18  0.039760          0.979872 -0.026790      0.998409\n",
       "   19  0.047923          0.977007 -0.028927      0.998597\n",
       "   20  0.046054          0.979229 -0.031299      0.998945\n",
       "   21  0.046872          0.975321 -0.033015      0.998903\n",
       "   22  0.058806          0.968924 -0.035215      0.999228\n",
       "   23  0.042341          0.978881 -0.036989      0.999243\n",
       "   24  0.043991          0.978935 -0.038980      0.999496\n",
       "   25  0.048413          0.979497 -0.040865      0.999586\n",
       "   26  0.064484          0.971226 -0.042656      0.999639\n",
       "   27  0.045710          0.976847 -0.044296      0.999535,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.189924          0.968175  0.375357      0.915995\n",
       "   1   0.125519          0.969781  0.144406      0.970530\n",
       "   2   0.098095          0.972377  0.098802      0.974023\n",
       "   3   0.078357          0.976285  0.069754      0.978936\n",
       "   4   0.062590          0.979122  0.050534      0.983480\n",
       "   5   0.052002          0.981451  0.036852      0.986317\n",
       "   6   0.049444          0.982093  0.025747      0.988751\n",
       "   7   0.066681          0.971039  0.017032      0.990715\n",
       "   8   0.039940          0.983860  0.010211      0.991818\n",
       "   9   0.034387          0.982816  0.004342      0.992834\n",
       "   10  0.037679          0.979363 -0.000811      0.993996\n",
       "   11  0.034978          0.984181 -0.005391      0.994943\n",
       "   12  0.032603          0.981986 -0.009195      0.995533\n",
       "   13  0.031519          0.982521 -0.012899      0.996314\n",
       "   14  0.031037          0.983351 -0.016104      0.997131\n",
       "   15  0.031331          0.981263 -0.019031      0.997586\n",
       "   16  0.039922          0.978881 -0.021728      0.997935\n",
       "   17  0.042369          0.980112 -0.024136      0.998293\n",
       "   18  0.038116          0.979069 -0.026431      0.998456\n",
       "   19  0.033824          0.982575 -0.028692      0.998695\n",
       "   20  0.033045          0.980621 -0.030795      0.998978\n",
       "   21  0.039206          0.981558 -0.032727      0.999011\n",
       "   22  0.035704          0.977677 -0.034792      0.999321\n",
       "   23  0.038839          0.977302 -0.036697      0.999407\n",
       "   24  0.038043          0.978774 -0.038666      0.999559\n",
       "   25  0.039829          0.979738 -0.040458      0.999598\n",
       "   26  0.045961          0.978185 -0.042221      0.999604\n",
       "   27  0.035352          0.979791 -0.043975      0.999672\n",
       "   28  0.040192          0.980701 -0.045830      0.999699\n",
       "   29  0.043931          0.977516 -0.047523      0.999744\n",
       "   30  0.039700          0.979684 -0.049288      0.999812\n",
       "   31  0.045382          0.976900 -0.051042      0.999866,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.172018          0.970771  0.361623      0.930235\n",
       "   1   0.128959          0.972190  0.141676      0.970861\n",
       "   2   0.100897          0.973635  0.101279      0.974172\n",
       "   3   0.078161          0.977463  0.073620      0.978903\n",
       "   4   0.064574          0.979550  0.052197      0.983638\n",
       "   5   0.053731          0.981611  0.038206      0.986773\n",
       "   6   0.052072          0.981772  0.028183      0.988802\n",
       "   7   0.045965          0.982495  0.020054      0.990405\n",
       "   8   0.041213          0.983431  0.013210      0.991558\n",
       "   9   0.038559          0.982521  0.007550      0.992744\n",
       "   10  0.035658          0.982013  0.001999      0.993617\n",
       "   11  0.037810          0.981531 -0.002712      0.994547\n",
       "   12  0.036494          0.981076 -0.006734      0.995536\n",
       "   13  0.048471          0.973207 -0.010528      0.996329\n",
       "   14  0.034791          0.981130 -0.013631      0.996940\n",
       "   15  0.035981          0.979738 -0.016561      0.997539\n",
       "   16  0.045731          0.969888 -0.019318      0.997929\n",
       "   17  0.033520          0.980942 -0.021784      0.998179\n",
       "   18  0.060718          0.969218 -0.024163      0.998605\n",
       "   19  0.044400          0.976660 -0.026443      0.998775\n",
       "   20  0.034186          0.978506 -0.028538      0.998912\n",
       "   21  0.035458          0.980835 -0.030658      0.999133\n",
       "   22  0.036445          0.980112 -0.032713      0.999324\n",
       "   23  0.042157          0.978747 -0.034640      0.999398\n",
       "   24  0.043848          0.976740 -0.036461      0.999392\n",
       "   25  0.041458          0.977570 -0.038299      0.999517\n",
       "   26  0.041271          0.976312 -0.040119      0.999559\n",
       "   27  0.042600          0.979604 -0.041925      0.999705\n",
       "   28  0.046938          0.975964 -0.043719      0.999750]),\n",
       " ({'crf': True,\n",
       "   'use_pos': True,\n",
       "   'use_morpheme': True,\n",
       "   'use_word': False,\n",
       "   'embedding_matrix': None,\n",
       "   'embed_dim': 70,\n",
       "   'trainable': True,\n",
       "   'input_dropout': False,\n",
       "   'stack_lstm': 1,\n",
       "   'epochs': 100,\n",
       "   'early_stopping': True,\n",
       "   'patience': 20,\n",
       "   'min_delta': 0.0001,\n",
       "   'use_char': False,\n",
       "   'stack_cross': False,\n",
       "   'stack_double': False,\n",
       "   'rec_dropout': 0.1},\n",
       "  [(73.11243889190658, 71.06652587117213, 72.07496653279786),\n",
       "   (74.6727376209448, 68.79916098584164, 71.61572052401746),\n",
       "   (72.9381443298969, 71.28463476070529, 72.10191082802548)],\n",
       "  [    val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.154519          0.971708  0.349684      0.929806\n",
       "   1   0.091006          0.977355  0.116798      0.972190\n",
       "   2   0.066747          0.982307  0.076407      0.980039\n",
       "   3   0.056460          0.983485  0.053017      0.983236\n",
       "   4   0.045923          0.985011  0.038741      0.986231\n",
       "   5   0.042053          0.984074  0.027824      0.988829\n",
       "   6   0.035440          0.986483  0.018943      0.990775\n",
       "   7   0.036878          0.984663  0.011581      0.992220\n",
       "   8   0.029291          0.987580  0.005491      0.993266\n",
       "   9   0.028237          0.985145  0.000253      0.994350\n",
       "   10  0.026576          0.986670 -0.004494      0.995441\n",
       "   11  0.030715          0.987152 -0.008556      0.996421\n",
       "   12  0.028643          0.986510 -0.011936      0.996982\n",
       "   13  0.030285          0.985787 -0.015022      0.997732\n",
       "   14  0.040744          0.977195 -0.017866      0.998013\n",
       "   15  0.025932          0.985894 -0.020394      0.998409\n",
       "   16  0.025457          0.984556 -0.022779      0.998778\n",
       "   17  0.027096          0.986349 -0.025048      0.998984\n",
       "   18  0.036135          0.986322 -0.027184      0.999181\n",
       "   19  0.029458          0.984930 -0.029180      0.999282\n",
       "   20  0.030941          0.984716 -0.031247      0.999553\n",
       "   21  0.029091          0.983003 -0.033066      0.999577\n",
       "   22  0.033889          0.982521 -0.034981      0.999705\n",
       "   23  0.038374          0.981210 -0.036719      0.999657\n",
       "   24  0.036249          0.982655 -0.038527      0.999774\n",
       "   25  0.034288          0.985225 -0.040165      0.999765\n",
       "   26  0.031938          0.985145 -0.042008      0.999893\n",
       "   27  0.035560          0.983833 -0.043739      0.999875\n",
       "   28  0.045505          0.979042 -0.045396      0.999866,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.170817          0.967479  0.352020      0.922652\n",
       "   1   0.091749          0.973876  0.112064      0.972378\n",
       "   2   0.067156          0.978854  0.072409      0.980170\n",
       "   3   0.051977          0.980407  0.049127      0.983945\n",
       "   4   0.042797          0.982066  0.033716      0.986579\n",
       "   5   0.035296          0.985439  0.022750      0.989237\n",
       "   6   0.026303          0.986456  0.014322      0.990951\n",
       "   7   0.025186          0.985305  0.007589      0.992315\n",
       "   8   0.022340          0.986376  0.001737      0.993474\n",
       "   9   0.021662          0.987232 -0.002833      0.994473\n",
       "   10  0.018816          0.987313 -0.007242      0.995372\n",
       "   11  0.015960          0.986884 -0.010811      0.996144\n",
       "   12  0.017109          0.987259 -0.014329      0.996809\n",
       "   13  0.015646          0.986617 -0.017363      0.997366\n",
       "   14  0.034560          0.984047 -0.020266      0.997807\n",
       "   15  0.013751          0.985493 -0.022683      0.998173\n",
       "   16  0.036805          0.975241 -0.025136      0.998439\n",
       "   17  0.015118          0.986028 -0.027390      0.998611\n",
       "   18  0.010749          0.985519 -0.029563      0.998981\n",
       "   19  0.014947          0.985037 -0.031645      0.999046\n",
       "   20  0.012115          0.986108 -0.033626      0.999234\n",
       "   21  0.014356          0.985921 -0.035562      0.999374\n",
       "   22  0.011712          0.984823 -0.037621      0.999499\n",
       "   23  0.010482          0.986804 -0.039427      0.999559\n",
       "   24  0.015027          0.985733 -0.041302      0.999738\n",
       "   25  0.011834          0.985064 -0.042981      0.999642\n",
       "   26  0.015370          0.986162 -0.044840      0.999750\n",
       "   27  0.012873          0.984154 -0.046533      0.999806\n",
       "   28  0.015892          0.982200 -0.048269      0.999827\n",
       "   29  0.015615          0.984368 -0.049969      0.999869,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.164495          0.970717  0.373391      0.922744\n",
       "   1   0.128508          0.966461  0.122483      0.972187\n",
       "   2   0.072443          0.981076  0.080212      0.979723\n",
       "   3   0.058186          0.982441  0.056175      0.983534\n",
       "   4   0.047488          0.983298  0.040452      0.986055\n",
       "   5   0.036865          0.985546  0.029125      0.988385\n",
       "   6   0.034840          0.985252  0.020438      0.990328\n",
       "   7   0.030800          0.986991  0.012977      0.991812\n",
       "   8   0.030521          0.986483  0.006820      0.992986\n",
       "   9   0.025908          0.985707  0.001268      0.994082\n",
       "   10  0.034583          0.978399 -0.003193      0.994857\n",
       "   11  0.032892          0.979149 -0.007245      0.995837\n",
       "   12  0.026250          0.981718 -0.010797      0.996511\n",
       "   13  0.018929          0.987794 -0.014067      0.997277\n",
       "   14  0.019062          0.987714 -0.016801      0.997574\n",
       "   15  0.019231          0.986858 -0.019860      0.998167\n",
       "   16  0.026229          0.982281 -0.022040      0.998352\n",
       "   17  0.016933          0.986536 -0.024557      0.998641\n",
       "   18  0.017395          0.985787 -0.026712      0.998814\n",
       "   19  0.025088          0.980567 -0.028903      0.999118\n",
       "   20  0.015952          0.985252 -0.030967      0.999213\n",
       "   21  0.017081          0.985064 -0.032988      0.999371\n",
       "   22  0.019212          0.984261 -0.034811      0.999401\n",
       "   23  0.016538          0.984984 -0.036657      0.999485\n",
       "   24  0.020028          0.983485 -0.038634      0.999720\n",
       "   25  0.017866          0.985011 -0.040374      0.999684\n",
       "   26  0.015349          0.985626 -0.042092      0.999738\n",
       "   27  0.019380          0.984342 -0.040123      0.998918\n",
       "   28  0.016243          0.983458 -0.045546      0.999821\n",
       "   29  0.018325          0.983672 -0.047255      0.999785\n",
       "   30  0.014233          0.985225 -0.048847      0.999774\n",
       "   31  0.019167          0.984984 -0.050653      0.999806\n",
       "   32  0.017111          0.983217 -0.052386      0.999905\n",
       "   33  0.023312          0.980942 -0.054114      0.999988]),\n",
       " ({'crf': True,\n",
       "   'use_pos': False,\n",
       "   'embedding_matrix': 'fastext',\n",
       "   'trainable': True,\n",
       "   'embed_dim': 300,\n",
       "   'use_morpheme': True,\n",
       "   'use_word': False,\n",
       "   'input_dropout': False,\n",
       "   'stack_lstm': 1,\n",
       "   'epochs': 100,\n",
       "   'early_stopping': True,\n",
       "   'patience': 20,\n",
       "   'min_delta': 0.0001,\n",
       "   'use_char': False,\n",
       "   'stack_cross': False,\n",
       "   'stack_double': False,\n",
       "   'rec_dropout': 0.1},\n",
       "  [(77.7602523659306, 78.08870116156284, 77.9241306638567),\n",
       "   (76.30753138075313, 76.50760356581017, 76.40743650170201),\n",
       "   (81.04683195592285, 74.1057934508816, 77.42105263157893)],\n",
       "  [    val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.106272          0.975964  0.266918      0.945086\n",
       "   1   0.073002          0.980889  0.078720      0.979479\n",
       "   2   0.046213          0.985760  0.047256      0.985614\n",
       "   3   0.037274          0.987286  0.029053      0.989493\n",
       "   4   0.044448          0.982575  0.017490      0.991785\n",
       "   5   0.038421          0.984234  0.008740      0.993945\n",
       "   6   0.036676          0.987714  0.001883      0.995441\n",
       "   7   0.023298          0.989052 -0.003837      0.996907\n",
       "   8   0.023880          0.989213 -0.008487      0.997759\n",
       "   9   0.023911          0.989963 -0.012269      0.998552\n",
       "   10  0.026640          0.988812 -0.015652      0.999261\n",
       "   11  0.026107          0.989213 -0.018086      0.999374\n",
       "   12  0.026882          0.989133 -0.020453      0.999672\n",
       "   13  0.027530          0.988892 -0.022396      0.999753\n",
       "   14  0.029364          0.989213 -0.024447      0.999899\n",
       "   15  0.029694          0.989026 -0.026200      0.999908\n",
       "   16  0.064514          0.979711 -0.027934      0.999928\n",
       "   17  0.032859          0.989748 -0.029565      0.999893\n",
       "   18  0.032032          0.989106 -0.031353      0.999952\n",
       "   19  0.032044          0.988758 -0.033046      0.999976\n",
       "   20  0.034176          0.989186 -0.034733      0.999973\n",
       "   21  0.039240          0.989427 -0.036403      1.000000\n",
       "   22  0.037513          0.989561 -0.038007      0.999973\n",
       "   23  0.036686          0.988892 -0.039623      0.999958\n",
       "   24  0.032369          0.989160 -0.041299      0.999976\n",
       "   25  0.034418          0.989374 -0.042945      0.999964\n",
       "   26  0.034355          0.988785 -0.044558      0.999955\n",
       "   27  0.040467          0.988517 -0.046175      0.999940\n",
       "   28  0.028140          0.988999 -0.047737      0.999923\n",
       "   29  0.028741          0.989026 -0.049435      0.999931,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.112344          0.971119  0.299427      0.941290\n",
       "   1   0.063989          0.980166  0.075500      0.980080\n",
       "   2   0.043338          0.984716  0.045224      0.985828\n",
       "   3   0.032504          0.986724  0.028050      0.989648\n",
       "   4   0.025304          0.988410  0.016417      0.992011\n",
       "   5   0.023154          0.988169  0.008003      0.993650\n",
       "   6   0.021558          0.987580  0.001145      0.995569\n",
       "   7   0.016592          0.989213 -0.004258      0.996824\n",
       "   8   0.016348          0.989267 -0.008721      0.997634\n",
       "   9   0.015907          0.989668 -0.012558      0.998376\n",
       "   10  0.024594          0.988865 -0.015598      0.998990\n",
       "   11  0.019454          0.988169 -0.018159      0.999279\n",
       "   12  0.022939          0.989347 -0.020697      0.999574\n",
       "   13  0.018932          0.988704 -0.022724      0.999648\n",
       "   14  0.025432          0.988865 -0.024755      0.999821\n",
       "   15  0.021142          0.989160 -0.026545      0.999896\n",
       "   16  0.021139          0.988678 -0.028250      0.999872\n",
       "   17  0.026406          0.987393 -0.030032      0.999893\n",
       "   18  0.023512          0.989213 -0.031708      0.999917\n",
       "   19  0.047088          0.983485 -0.033360      0.999946\n",
       "   20  0.025567          0.989615 -0.035060      0.999940\n",
       "   21  0.028067          0.988758 -0.036774      0.999985\n",
       "   22  0.026810          0.989695 -0.038400      0.999973\n",
       "   23  0.026817          0.989427 -0.040030      0.999967\n",
       "   24  0.026809          0.989347 -0.041628      0.999949\n",
       "   25  0.025539          0.989079 -0.043257      0.999961\n",
       "   26  0.025263          0.988758 -0.044831      0.999875\n",
       "   27  0.022030          0.989267 -0.046595      0.999970\n",
       "   28  0.025432          0.989802 -0.048105      0.999949\n",
       "   29  0.021443          0.989160 -0.049758      0.999952\n",
       "   30  0.053900          0.982200 -0.051410      0.999896\n",
       "   31  0.026288          0.988437 -0.053158      0.999943\n",
       "   32  0.031851          0.985546 -0.054843      0.999982\n",
       "   33  0.021599          0.989802 -0.056458      0.999955\n",
       "   34  0.023791          0.988731 -0.058135      0.999982\n",
       "   35  0.021726          0.989748 -0.059716      0.999943\n",
       "   36  0.024155          0.988142 -0.061459      0.999991\n",
       "   37  0.019464          0.989106 -0.063073      0.999970\n",
       "   38  0.019247          0.989347 -0.064714      0.999979\n",
       "   39  0.014588          0.989802 -0.066356      0.999976\n",
       "   40  0.022806          0.989588 -0.068045      1.000000\n",
       "   41  0.044796          0.984690 -0.069558      0.999937\n",
       "   42  0.020419          0.989561 -0.071311      0.999997\n",
       "   43  0.033035          0.987045 -0.072971      1.000000\n",
       "   44  0.018817          0.989454 -0.074592      0.999991\n",
       "   45  0.015798          0.989320 -0.076242      1.000000\n",
       "   46  0.022266          0.989615 -0.077898      1.000000\n",
       "   47  0.018232          0.989722 -0.079522      1.000000\n",
       "   48  0.021702          0.988678 -0.081178      1.000000,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.114641          0.974358  0.284710      0.947583\n",
       "   1   0.072483          0.980782  0.082797      0.979294\n",
       "   2   0.050449          0.984957  0.051496      0.985292\n",
       "   3   0.037714          0.987313  0.033611      0.988871\n",
       "   4   0.030979          0.987875  0.021866      0.991338\n",
       "   5   0.025980          0.989293  0.013094      0.993191\n",
       "   6   0.025028          0.989400  0.005878      0.995051\n",
       "   7   0.026466          0.989106 -0.000131      0.996645\n",
       "   8   0.021476          0.988169 -0.004622      0.997414\n",
       "   9   0.026018          0.984716 -0.008470      0.998209\n",
       "   10  0.021151          0.988651 -0.011814      0.998957\n",
       "   11  0.023106          0.989160 -0.014477      0.999356\n",
       "   12  0.022156          0.987420 -0.017028      0.999607\n",
       "   13  0.023273          0.987875 -0.019019      0.999663\n",
       "   14  0.027660          0.989320 -0.021060      0.999818\n",
       "   15  0.026593          0.988357 -0.022855      0.999863\n",
       "   16  0.023743          0.988276 -0.024637      0.999905\n",
       "   17  0.025416          0.989133 -0.026358      0.999940\n",
       "   18  0.027579          0.988892 -0.028116      0.999955\n",
       "   19  0.025245          0.988169 -0.029799      0.999958\n",
       "   20  0.027644          0.989293 -0.031446      0.999961\n",
       "   21  0.028462          0.988678 -0.033109      0.999976\n",
       "   22  0.033981          0.988678 -0.034812      1.000000\n",
       "   23  0.031885          0.989079 -0.036398      0.999964\n",
       "   24  0.029872          0.989026 -0.037975      0.999970\n",
       "   25  0.027706          0.988678 -0.039581      0.999961\n",
       "   26  0.031811          0.988624 -0.041344      0.999973]),\n",
       " ({'crf': True,\n",
       "   'use_pos': True,\n",
       "   'embedding_matrix': 'fastext',\n",
       "   'trainable': True,\n",
       "   'embed_dim': 300,\n",
       "   'use_morpheme': True,\n",
       "   'use_word': False,\n",
       "   'input_dropout': False,\n",
       "   'stack_lstm': 1,\n",
       "   'epochs': 100,\n",
       "   'early_stopping': True,\n",
       "   'patience': 20,\n",
       "   'min_delta': 0.0001,\n",
       "   'use_char': False,\n",
       "   'stack_cross': False,\n",
       "   'stack_double': False,\n",
       "   'rec_dropout': 0.1},\n",
       "  [(81.0481736368449, 80.83421330517423, 80.94105207507269),\n",
       "   (80.71772897696839, 79.02464604090194, 79.8622151563328),\n",
       "   (80.66496163682865, 79.44584382871537, 80.0507614213198)],\n",
       "  [    val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.095237          0.977730  0.284047      0.944425\n",
       "   1   0.058320          0.984529  0.072784      0.981454\n",
       "   2   0.059309          0.985225  0.042491      0.987443\n",
       "   3   0.051364          0.979524  0.026546      0.990533\n",
       "   4   0.039736          0.984395  0.015736      0.992557\n",
       "   5   0.033864          0.986858  0.008082      0.994210\n",
       "   6   0.023241          0.989909  0.001757      0.995581\n",
       "   7   0.022205          0.989802 -0.003552      0.997044\n",
       "   8   0.043531          0.987446 -0.008197      0.998129\n",
       "   9   0.023945          0.989213 -0.011605      0.998769\n",
       "   10  0.022778          0.989240 -0.014497      0.999181\n",
       "   11  0.024978          0.988624 -0.017126      0.999479\n",
       "   12  0.025413          0.990123 -0.019310      0.999642\n",
       "   13  0.030164          0.990310 -0.021377      0.999750\n",
       "   14  0.039396          0.989855 -0.023196      0.999839\n",
       "   15  0.029603          0.989160 -0.025038      0.999914\n",
       "   16  0.032367          0.989936 -0.026802      0.999946\n",
       "   17  0.032736          0.989133 -0.028526      0.999982\n",
       "   18  0.033006          0.989534 -0.030184      0.999976\n",
       "   19  0.035830          0.989454 -0.031838      0.999976\n",
       "   20  0.038470          0.988972 -0.033523      0.999985\n",
       "   21  0.033187          0.989454 -0.035159      0.999979\n",
       "   22  0.034712          0.989963 -0.036823      0.999988\n",
       "   23  0.035557          0.989133 -0.038466      0.999991\n",
       "   24  0.040116          0.989882 -0.040087      0.999973\n",
       "   25  0.039402          0.989293 -0.041741      0.999991\n",
       "   26  0.042685          0.989133 -0.043395      0.999997\n",
       "   27  0.038576          0.989240 -0.045003      0.999976\n",
       "   28  0.036925          0.989106 -0.046662      0.999973\n",
       "   29  0.042288          0.989133 -0.048259      0.999958\n",
       "   30  0.035987          0.989320 -0.049926      0.999973\n",
       "   31  0.037057          0.988812 -0.051596      0.999979\n",
       "   32  0.034400          0.988249 -0.053211      0.999979\n",
       "   33  0.032886          0.988812 -0.054786      0.999928,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.104378          0.973260  0.271224      0.949645\n",
       "   1   0.062692          0.981986  0.076577      0.980918\n",
       "   2   0.042289          0.985359  0.045721      0.986290\n",
       "   3   0.031488          0.987259  0.027938      0.990387\n",
       "   4   0.038332          0.985894  0.016596      0.992649\n",
       "   5   0.030369          0.986590  0.008685      0.994282\n",
       "   6   0.017697          0.989427  0.002424      0.995694\n",
       "   7   0.018211          0.989695 -0.003207      0.997047\n",
       "   8   0.016348          0.989641 -0.007445      0.998096\n",
       "   9   0.017287          0.989427 -0.010918      0.998737\n",
       "   10  0.019020          0.990337 -0.013912      0.999100\n",
       "   11  0.018936          0.990926 -0.016441      0.999425\n",
       "   12  0.014473          0.990953 -0.018626      0.999598\n",
       "   13  0.015189          0.989882 -0.020676      0.999759\n",
       "   14  0.027345          0.989829 -0.022646      0.999821\n",
       "   15  0.022305          0.990203 -0.024492      0.999926\n",
       "   16  0.017274          0.990471 -0.026131      0.999911\n",
       "   17  0.017000          0.990739 -0.027844      0.999911\n",
       "   18  0.017911          0.990310 -0.029624      0.999955\n",
       "   19  0.016608          0.990551 -0.031293      0.999985\n",
       "   20  0.016854          0.990578 -0.032935      0.999970\n",
       "   21  0.018081          0.989748 -0.034569      0.999967\n",
       "   22  0.018316          0.989320 -0.036158      0.999934\n",
       "   23  0.019984          0.990123 -0.037881      0.999973\n",
       "   24  0.018515          0.990337 -0.039549      0.999985\n",
       "   25  0.015061          0.989855 -0.041177      0.999967\n",
       "   26  0.018249          0.990096 -0.042802      0.999955\n",
       "   27  0.015592          0.990230 -0.044479      0.999985\n",
       "   28  0.014605          0.990096 -0.046097      0.999970\n",
       "   29  0.018442          0.989507 -0.047763      0.999982\n",
       "   30  0.014523          0.990391 -0.049418      0.999988\n",
       "   31  0.010956          0.989882 -0.050981      0.999949,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.106514          0.976660  0.260892      0.953713\n",
       "   1   0.064581          0.983244  0.077572      0.980667\n",
       "   2   0.045927          0.987072  0.045490      0.987363\n",
       "   3   0.037109          0.988357  0.028848      0.990626\n",
       "   4   0.038439          0.986858  0.018458      0.992622\n",
       "   5   0.023624          0.991301  0.010324      0.994559\n",
       "   6   0.021671          0.990819  0.004387      0.996034\n",
       "   7   0.020025          0.990980 -0.000745      0.997199\n",
       "   8   0.021933          0.989320 -0.004737      0.998051\n",
       "   9   0.019131          0.990391 -0.008102      0.998769\n",
       "   10  0.021304          0.989989 -0.011204      0.999291\n",
       "   11  0.022828          0.990096 -0.013593      0.999464\n",
       "   12  0.021185          0.990605 -0.015846      0.999714\n",
       "   13  0.020642          0.990016 -0.017733      0.999756\n",
       "   14  0.022371          0.990471 -0.019628      0.999845\n",
       "   15  0.024097          0.990230 -0.021470      0.999866\n",
       "   16  0.023029          0.989936 -0.023222      0.999917\n",
       "   17  0.024216          0.990444 -0.024928      0.999949\n",
       "   18  0.024801          0.989320 -0.026662      0.999970\n",
       "   19  0.024160          0.990578 -0.028321      0.999967\n",
       "   20  0.029280          0.989855 -0.029997      1.000000\n",
       "   21  0.028389          0.989374 -0.031662      0.999997\n",
       "   22  0.028623          0.990150 -0.033301      0.999991\n",
       "   23  0.028301          0.989641 -0.034786      0.999917\n",
       "   24  0.041686          0.984368 -0.036574      0.999970\n",
       "   25  0.024455          0.989748 -0.038137      0.999967]),\n",
       " ({'use_char': True,\n",
       "   'crf': True,\n",
       "   'use_pos': False,\n",
       "   'use_morpheme': True,\n",
       "   'use_word': False,\n",
       "   'embedding_matrix': None,\n",
       "   'embed_dim': 70,\n",
       "   'trainable': True,\n",
       "   'input_dropout': False,\n",
       "   'stack_lstm': 1,\n",
       "   'epochs': 100,\n",
       "   'early_stopping': True,\n",
       "   'patience': 20,\n",
       "   'min_delta': 0.0001,\n",
       "   'stack_cross': False,\n",
       "   'stack_double': False,\n",
       "   'rec_dropout': 0.1},\n",
       "  [(80.94905792044662, 61.246040126715954, 69.73249173429517),\n",
       "   (72.96969696969697, 63.13581541688515, 67.69749789148159),\n",
       "   (70.72921978582356, 69.87405541561714, 70.29903699949315)],\n",
       "  [    val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.164615          0.971601  0.360430      0.929461\n",
       "   1   0.118684          0.973394  0.140340      0.970304\n",
       "   2   0.099093          0.975000  0.104268      0.973045\n",
       "   3   0.076383          0.979202  0.077402      0.977393\n",
       "   4   0.064482          0.981237  0.057988      0.981165\n",
       "   5   0.070802          0.969513  0.045043      0.983641\n",
       "   6   0.048630          0.982575  0.035356      0.985766\n",
       "   7   0.044320          0.981879  0.027224      0.987241\n",
       "   8   0.041078          0.984449  0.020275      0.988683\n",
       "   9   0.034230          0.983646  0.013996      0.990003\n",
       "   10  0.031231          0.984797  0.008782      0.990840\n",
       "   11  0.032077          0.981611  0.003743      0.991785\n",
       "   12  0.026305          0.983887 -0.000542      0.992703\n",
       "   13  0.026653          0.981879 -0.004788      0.993698\n",
       "   14  0.023590          0.982655 -0.008232      0.994094\n",
       "   15  0.020937          0.985546 -0.011244      0.994508\n",
       "   16  0.019414          0.984850 -0.014585      0.995244\n",
       "   17  0.018807          0.981986 -0.017439      0.995635\n",
       "   18  0.017615          0.982307 -0.020084      0.996046\n",
       "   19  0.015954          0.982414 -0.022959      0.996573\n",
       "   20  0.014653          0.983753 -0.025386      0.996764\n",
       "   21  0.013294          0.982923 -0.027514      0.997119\n",
       "   22  0.010770          0.983940 -0.029889      0.997375\n",
       "   23  0.027343          0.970664 -0.032014      0.997569\n",
       "   24  0.011525          0.980273 -0.034110      0.997831\n",
       "   25  0.025453          0.971360 -0.036325      0.998191\n",
       "   26  0.009247          0.984529 -0.038356      0.998275\n",
       "   27  0.013515          0.977115 -0.040301      0.998516\n",
       "   28  0.016171          0.974893 -0.042182      0.998677\n",
       "   29  0.013526          0.977703 -0.044307      0.998865\n",
       "   30  0.005336          0.983217 -0.046142      0.998808\n",
       "   31  0.008597          0.982602 -0.047983      0.999014\n",
       "   32  0.008902          0.981317 -0.049835      0.998972\n",
       "   33  0.012654          0.977891 -0.051619      0.999097\n",
       "   34  0.006879          0.978988 -0.053474      0.999282\n",
       "   35  0.011970          0.975000 -0.055126      0.999282,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.173353          0.968175  0.350602      0.930393\n",
       "   1   0.126152          0.969941  0.135904      0.970900\n",
       "   2   0.100042          0.971788  0.099897      0.973826\n",
       "   3   0.072961          0.977382  0.073856      0.978358\n",
       "   4   0.056600          0.979363  0.054354      0.981806\n",
       "   5   0.049432          0.980139  0.041241      0.984547\n",
       "   6   0.043286          0.981103  0.031107      0.986600\n",
       "   7   0.034998          0.984368  0.022574      0.988310\n",
       "   8   0.035803          0.980648  0.015549      0.989663\n",
       "   9   0.032823          0.983887  0.009494      0.990796\n",
       "   10  0.023598          0.983913  0.004732      0.991833\n",
       "   11  0.027357          0.982200 -0.000069      0.992512\n",
       "   12  0.024304          0.984904 -0.004377      0.993415\n",
       "   13  0.018265          0.986001 -0.007822      0.993880\n",
       "   14  0.016232          0.983672 -0.011196      0.994681\n",
       "   15  0.017381          0.984716 -0.014688      0.995185\n",
       "   16  0.015008          0.983217 -0.017414      0.995602\n",
       "   17  0.013844          0.983298 -0.020299      0.996079\n",
       "   18  0.009266          0.985332 -0.022952      0.996362\n",
       "   19  0.016296          0.978774 -0.025347      0.996847\n",
       "   20  0.010361          0.982147 -0.027907      0.997294\n",
       "   21  0.006716          0.984074 -0.030263      0.997536\n",
       "   22  0.010639          0.981879 -0.032366      0.997646\n",
       "   23  0.010296          0.980996 -0.034712      0.997920\n",
       "   24  0.009439          0.982655 -0.036643      0.998212\n",
       "   25  0.009367          0.982013 -0.039005      0.998647\n",
       "   26  0.008462          0.982709 -0.040723      0.998531\n",
       "   27  0.020212          0.972216 -0.042719      0.998760\n",
       "   28  0.003769          0.982147 -0.044586      0.998659\n",
       "   29  0.005059          0.981290 -0.046511      0.998993\n",
       "   30  0.004788          0.980969 -0.048235      0.998942\n",
       "   31  0.001791          0.982575 -0.050083      0.999112\n",
       "   32  0.003988          0.982521 -0.052034      0.999255\n",
       "   33  0.005743          0.980889 -0.053874      0.999380,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.165502          0.970798  0.354253      0.929106\n",
       "   1   0.135657          0.970155  0.135188      0.971067\n",
       "   2   0.109697          0.973688  0.100373      0.973743\n",
       "   3   0.073378          0.978667  0.073959      0.978141\n",
       "   4   0.069414          0.978319  0.054953      0.981505\n",
       "   5   0.052297          0.979738  0.042244      0.984121\n",
       "   6   0.049920          0.980327  0.032517      0.985989\n",
       "   7   0.038764          0.981638  0.024119      0.987911\n",
       "   8   0.034493          0.983191  0.017176      0.989067\n",
       "   9   0.036743          0.983324  0.011136      0.990310\n",
       "   10  0.026626          0.982414  0.005814      0.991055\n",
       "   11  0.024933          0.982120  0.000891      0.991987\n",
       "   12  0.031876          0.984020 -0.003251      0.993123\n",
       "   13  0.019401          0.984716 -0.006952      0.993662\n",
       "   14  0.019185          0.981076 -0.010783      0.994583\n",
       "   15  0.016661          0.981959 -0.014076      0.995158\n",
       "   16  0.014892          0.983806 -0.016979      0.995405\n",
       "   17  0.013186          0.983084 -0.019789      0.995933\n",
       "   18  0.014309          0.981772 -0.022674      0.996615\n",
       "   19  0.011650          0.984850 -0.025241      0.996898\n",
       "   20  0.009430          0.983565 -0.027543      0.997077\n",
       "   21  0.010754          0.983779 -0.029955      0.997574\n",
       "   22  0.008692          0.981933 -0.032152      0.997667\n",
       "   23  0.013001          0.979764 -0.034403      0.997941\n",
       "   24  0.007409          0.982013 -0.036385      0.998129\n",
       "   25  0.006581          0.982414 -0.038436      0.998477\n",
       "   26  0.007023          0.981852 -0.040388      0.998471\n",
       "   27  0.006211          0.982709 -0.042400      0.998749\n",
       "   28  0.005172          0.982575 -0.044270      0.998814\n",
       "   29  0.003143          0.983378 -0.046009      0.998743\n",
       "   30  0.006140          0.980246 -0.048121      0.999112\n",
       "   31  0.006671          0.981692 -0.049896      0.999070\n",
       "   32  0.005213          0.982254 -0.051787      0.999178\n",
       "   33  0.007989          0.982334 -0.053595      0.999425\n",
       "   34  0.008056          0.977222 -0.055194      0.999219\n",
       "   35  0.000847          0.981558 -0.057013      0.999392\n",
       "   36  0.003917          0.981772 -0.058865      0.999401\n",
       "   37  0.002516          0.980915 -0.060484      0.999467\n",
       "   38  0.004716          0.979898 -0.062201      0.999532\n",
       "   39  0.002951          0.978747 -0.063934      0.999547]),\n",
       " ({'use_char': True,\n",
       "   'crf': True,\n",
       "   'use_pos': True,\n",
       "   'use_morpheme': True,\n",
       "   'use_word': False,\n",
       "   'embedding_matrix': None,\n",
       "   'embed_dim': 70,\n",
       "   'trainable': True,\n",
       "   'input_dropout': False,\n",
       "   'stack_lstm': 1,\n",
       "   'epochs': 100,\n",
       "   'early_stopping': True,\n",
       "   'patience': 20,\n",
       "   'min_delta': 0.0001,\n",
       "   'stack_cross': False,\n",
       "   'stack_double': False,\n",
       "   'rec_dropout': 0.1},\n",
       "  [(75.57702630166399, 74.34002111932418, 74.95342028214),\n",
       "   (73.40534979423869, 74.82957524908232, 74.1106206180213),\n",
       "   (77.78364116094987, 74.25692695214106, 75.97938144329896)],\n",
       "  [    val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.162898          0.971467  0.355297      0.929687\n",
       "   1   0.098327          0.976151  0.115261      0.972887\n",
       "   2   0.068261          0.982173  0.078480      0.979216\n",
       "   3   0.066264          0.981424  0.057902      0.981901\n",
       "   4   0.049056          0.983378  0.044269      0.983936\n",
       "   5   0.041895          0.983726  0.034104      0.986362\n",
       "   6   0.036603          0.984609  0.025778      0.987798\n",
       "   7   0.032462          0.985787  0.018995      0.989458\n",
       "   8   0.027202          0.985814  0.012975      0.990432\n",
       "   9   0.024766          0.986884  0.007586      0.991466\n",
       "   10  0.021462          0.986831  0.002309      0.992691\n",
       "   11  0.019931          0.985921 -0.001789      0.993418\n",
       "   12  0.017057          0.986215 -0.005763      0.994172\n",
       "   13  0.016875          0.984743 -0.009251      0.994487\n",
       "   14  0.015094          0.985600 -0.012468      0.995164\n",
       "   15  0.029004          0.976044 -0.015473      0.995554\n",
       "   16  0.012003          0.986483 -0.018529      0.996350\n",
       "   17  0.011515          0.984930 -0.021069      0.996719\n",
       "   18  0.010456          0.987179 -0.023545      0.997092\n",
       "   19  0.007880          0.986081 -0.025911      0.997360\n",
       "   20  0.009356          0.988142 -0.028314      0.997703\n",
       "   21  0.008201          0.986376 -0.030578      0.998090\n",
       "   22  0.008448          0.985546 -0.032583      0.998084\n",
       "   23  0.005353          0.986429 -0.034791      0.998325\n",
       "   24  0.004858          0.986135 -0.036465      0.998465\n",
       "   25  0.006823          0.982521 -0.038740      0.998570\n",
       "   26  0.006482          0.986188 -0.040877      0.998942\n",
       "   27  0.004277          0.984208 -0.042643      0.998900\n",
       "   28  0.010033          0.980541 -0.044499      0.999124\n",
       "   29  0.004081          0.983485 -0.046433      0.999246\n",
       "   30  0.003327          0.984261 -0.048082      0.999240\n",
       "   31  0.003518          0.984342 -0.050102      0.999467\n",
       "   32  0.002222          0.985225 -0.051806      0.999416\n",
       "   33  0.002581          0.985519 -0.053579      0.999499\n",
       "   34  0.001079          0.984770 -0.055313      0.999574\n",
       "   35  0.002693          0.982682 -0.057069      0.999601\n",
       "   36  0.000567          0.985680 -0.058825      0.999636\n",
       "   37  0.000219          0.986563 -0.060535      0.999744\n",
       "   38  0.003303          0.981103 -0.062186      0.999750\n",
       "   39 -0.002092          0.985091 -0.063811      0.999708\n",
       "   40 -0.000869          0.984663 -0.065571      0.999756,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.168589          0.967639  0.348833      0.931234\n",
       "   1   0.102759          0.973876  0.112987      0.972899\n",
       "   2   0.066442          0.978587  0.076869      0.978990\n",
       "   3   0.056597          0.981290  0.056203      0.982026\n",
       "   4   0.046606          0.981478  0.044256      0.984219\n",
       "   5   0.036914          0.984315  0.034226      0.986105\n",
       "   6   0.032568          0.985385  0.026154      0.987840\n",
       "   7   0.024253          0.985733  0.018486      0.989338\n",
       "   8   0.021304          0.985385  0.011849      0.990980\n",
       "   9   0.018571          0.987500  0.006403      0.991779\n",
       "   10  0.016122          0.987313  0.001578      0.992554\n",
       "   11  0.013218          0.987768 -0.002679      0.993579\n",
       "   12  0.008661          0.988169 -0.006713      0.994222\n",
       "   13  0.009396          0.986697 -0.010129      0.994967\n",
       "   14  0.006662          0.988035 -0.013586      0.995819\n",
       "   15  0.006538          0.985305 -0.016233      0.995974\n",
       "   16  0.003895          0.986965 -0.019237      0.996567\n",
       "   17  0.003537          0.986590 -0.021519      0.996803\n",
       "   18  0.002329          0.985921 -0.024324      0.997303\n",
       "   19  0.005267          0.984074 -0.026661      0.997688\n",
       "   20 -0.001452          0.986911 -0.028823      0.997890\n",
       "   21 -0.000177          0.985814 -0.031058      0.998176\n",
       "   22 -0.001309          0.985519 -0.033077      0.998090\n",
       "   23 -0.002740          0.986429 -0.035323      0.998644\n",
       "   24 -0.004102          0.986697 -0.036808      0.998537\n",
       "   25 -0.005471          0.987098 -0.039212      0.998889\n",
       "   26 -0.004043          0.986349 -0.041077      0.998930\n",
       "   27 -0.005983          0.987072 -0.042937      0.999014\n",
       "   28 -0.006595          0.987339 -0.044767      0.999240\n",
       "   29 -0.006627          0.985118 -0.046539      0.999148\n",
       "   30 -0.005520          0.986403 -0.048367      0.999336\n",
       "   31 -0.010221          0.986162 -0.050277      0.999458\n",
       "   32 -0.010951          0.985787 -0.051994      0.999473,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.152504          0.970771  0.372105      0.926722\n",
       "   1   0.105845          0.975214  0.118986      0.972083\n",
       "   2   0.083754          0.978747  0.082101      0.978531\n",
       "   3   0.054976          0.982334  0.059506      0.981764\n",
       "   4   0.051501          0.981799  0.045932      0.983999\n",
       "   5   0.040451          0.984208  0.035803      0.985721\n",
       "   6   0.033144          0.986242  0.027787      0.987718\n",
       "   7   0.027353          0.987018  0.020422      0.989356\n",
       "   8   0.034908          0.983217  0.014027      0.990340\n",
       "   9   0.024954          0.986055  0.008516      0.991225\n",
       "   10  0.016245          0.987955  0.003553      0.992300\n",
       "   11  0.013423          0.987366 -0.000968      0.993194\n",
       "   12  0.016044          0.987446 -0.005204      0.993939\n",
       "   13  0.011282          0.987098 -0.008690      0.994604\n",
       "   14  0.009674          0.987982 -0.012348      0.995221\n",
       "   15  0.006899          0.986670 -0.015483      0.995882\n",
       "   16  0.003697          0.987420 -0.018013      0.996183\n",
       "   17  0.003723          0.987741 -0.020868      0.996648\n",
       "   18  0.003612          0.986751 -0.023346      0.997214\n",
       "   19  0.001631          0.987714 -0.025642      0.997318\n",
       "   20  0.002493          0.986858 -0.027948      0.997533\n",
       "   21  0.000938          0.986162 -0.030193      0.997923\n",
       "   22  0.000480          0.986804 -0.032329      0.998150\n",
       "   23 -0.003971          0.987098 -0.034376      0.998302\n",
       "   24 -0.002854          0.986858 -0.036564      0.998474\n",
       "   25 -0.004766          0.985252 -0.038549      0.998641\n",
       "   26 -0.004704          0.984395 -0.040113      0.998781\n",
       "   27 -0.003563          0.984502 -0.042449      0.999035\n",
       "   28 -0.005564          0.983967 -0.044383      0.999121\n",
       "   29 -0.003751          0.987286 -0.046089      0.999121\n",
       "   30 -0.007433          0.985305 -0.047909      0.999219]),\n",
       " ({'use_char': True,\n",
       "   'crf': True,\n",
       "   'use_pos': False,\n",
       "   'embedding_matrix': 'fastext',\n",
       "   'trainable': True,\n",
       "   'embed_dim': 300,\n",
       "   'use_morpheme': True,\n",
       "   'use_word': False,\n",
       "   'input_dropout': False,\n",
       "   'stack_lstm': 1,\n",
       "   'epochs': 100,\n",
       "   'early_stopping': True,\n",
       "   'patience': 20,\n",
       "   'min_delta': 0.0001,\n",
       "   'stack_cross': False,\n",
       "   'stack_double': False,\n",
       "   'rec_dropout': 0.1},\n",
       "  [(83.2164058283864, 81.41499472016895, 82.30584467574059),\n",
       "   (80.12422360248446, 81.1746198217095, 80.646001562907),\n",
       "   (83.34179786693753, 82.67002518891687, 83.00455235204855)],\n",
       "  [    val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.110609          0.973233  0.293278      0.944625\n",
       "   1   0.069152          0.981263  0.086228      0.978212\n",
       "   2   0.052766          0.983458  0.055094      0.983436\n",
       "   3   0.042406          0.986188  0.037907      0.986788\n",
       "   4   0.032007          0.988999  0.026399      0.989055\n",
       "   5   0.028243          0.988785  0.017764      0.990721\n",
       "   6   0.022361          0.989855  0.011423      0.992175\n",
       "   7   0.020519          0.988490  0.005289      0.993644\n",
       "   8   0.020293          0.989320  0.000320      0.994642\n",
       "   9   0.017122          0.989026 -0.004031      0.995530\n",
       "   10  0.018330          0.989829 -0.007627      0.996085\n",
       "   11  0.014471          0.990685 -0.011169      0.996830\n",
       "   12  0.011686          0.988357 -0.014315      0.997569\n",
       "   13  0.010179          0.989668 -0.017218      0.997789\n",
       "   14  0.011605          0.988945 -0.019761      0.998400\n",
       "   15  0.008565          0.988731 -0.022308      0.998641\n",
       "   16  0.007137          0.989454 -0.024440      0.998844\n",
       "   17  0.005297          0.989427 -0.026610      0.999088\n",
       "   18  0.007789          0.990525 -0.028671      0.999190\n",
       "   19  0.007817          0.989615 -0.030702      0.999446\n",
       "   20  0.007971          0.989909 -0.032597      0.999526\n",
       "   21  0.006180          0.989641 -0.034423      0.999550\n",
       "   22  0.005445          0.989052 -0.036235      0.999669\n",
       "   23  0.004280          0.989400 -0.037930      0.999717\n",
       "   24  0.005557          0.990284 -0.039673      0.999720\n",
       "   25  0.000837          0.990310 -0.041467      0.999827\n",
       "   26 -0.001063          0.990632 -0.043124      0.999821\n",
       "   27 -0.000728          0.989267 -0.044755      0.999774\n",
       "   28  0.001373          0.989882 -0.046434      0.999812\n",
       "   29  0.000170          0.991060 -0.048239      0.999911\n",
       "   ..       ...               ...       ...           ...\n",
       "   32 -0.004866          0.990203 -0.053222      0.999928\n",
       "   33 -0.001623          0.990899 -0.054862      0.999905\n",
       "   34 -0.004414          0.990364 -0.056566      0.999943\n",
       "   35 -0.004086          0.990658 -0.058231      0.999967\n",
       "   36 -0.003320          0.990739 -0.059869      0.999949\n",
       "   37 -0.005037          0.990444 -0.061484      0.999943\n",
       "   38 -0.007362          0.989668 -0.063157      0.999914\n",
       "   39 -0.012114          0.990712 -0.064789      0.999952\n",
       "   40 -0.009994          0.990257 -0.066448      0.999961\n",
       "   41 -0.008306          0.991247 -0.068136      0.999973\n",
       "   42 -0.012562          0.991060 -0.069682      0.999908\n",
       "   43 -0.006451          0.991087 -0.071440      0.999967\n",
       "   44 -0.008187          0.988838 -0.073039      0.999952\n",
       "   45 -0.010936          0.989347 -0.074680      0.999955\n",
       "   46 -0.011436          0.989963 -0.076347      0.999970\n",
       "   47 -0.015152          0.990792 -0.077988      0.999967\n",
       "   48 -0.013609          0.989802 -0.079581      0.999946\n",
       "   49 -0.015781          0.991033 -0.081330      0.999991\n",
       "   50 -0.012080          0.991113 -0.082947      0.999964\n",
       "   51 -0.012295          0.990980 -0.084568      0.999973\n",
       "   52 -0.019417          0.989427 -0.086168      0.999931\n",
       "   53 -0.022943          0.990792 -0.087860      0.999979\n",
       "   54 -0.018640          0.990819 -0.089512      0.999973\n",
       "   55 -0.023345          0.989989 -0.091111      0.999914\n",
       "   56 -0.025432          0.990926 -0.092714      0.999934\n",
       "   57 -0.023339          0.990391 -0.094354      0.999961\n",
       "   58 -0.026250          0.990658 -0.096068      0.999961\n",
       "   59 -0.029729          0.989909 -0.097670      0.999940\n",
       "   60 -0.029054          0.990043 -0.099336      0.999961\n",
       "   61 -0.028080          0.990926 -0.101041      0.999985\n",
       "   \n",
       "   [62 rows x 4 columns],\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.119377          0.970717  0.283479      0.947220\n",
       "   1   0.077625          0.978480  0.087824      0.978233\n",
       "   2   0.050960          0.984261  0.057250      0.983531\n",
       "   3   0.043636          0.983779  0.039971      0.986841\n",
       "   4   0.028972          0.987875  0.028155      0.989181\n",
       "   5   0.026137          0.988035  0.019389      0.990775\n",
       "   6   0.021500          0.988678  0.012300      0.992384\n",
       "   7   0.024826          0.988303  0.006464      0.993403\n",
       "   8   0.016865          0.989481  0.001292      0.994523\n",
       "   9   0.021547          0.984716 -0.003593      0.995501\n",
       "   10  0.010433          0.989508 -0.006924      0.996123\n",
       "   11  0.011620          0.988758 -0.010668      0.997047\n",
       "   12  0.016456          0.985305 -0.013588      0.997411\n",
       "   13  0.006258          0.989240 -0.016697      0.998024\n",
       "   14  0.006393          0.990016 -0.019262      0.998322\n",
       "   15  0.005080          0.990230 -0.021521      0.998531\n",
       "   16  0.006073          0.990150 -0.023861      0.998972\n",
       "   17  0.001534          0.990739 -0.025868      0.998990\n",
       "   18  0.002396          0.989829 -0.027949      0.999231\n",
       "   19  0.003912          0.989534 -0.029771      0.999237\n",
       "   20  0.001760          0.989829 -0.031847      0.999398\n",
       "   21 -0.000222          0.989775 -0.033717      0.999508\n",
       "   22  0.000986          0.990070 -0.035660      0.999735\n",
       "   23 -0.002363          0.990364 -0.037261      0.999657\n",
       "   24 -0.002037          0.990605 -0.038975      0.999657\n",
       "   25 -0.001868          0.990310 -0.040734      0.999750\n",
       "   26 -0.001987          0.990177 -0.042513      0.999777\n",
       "   27 -0.003903          0.989989 -0.044090      0.999812\n",
       "   28 -0.007064          0.990123 -0.045828      0.999765\n",
       "   29 -0.006610          0.990257 -0.047590      0.999863\n",
       "   30 -0.005779          0.990177 -0.049227      0.999878\n",
       "   31 -0.007297          0.989347 -0.050916      0.999881\n",
       "   32 -0.004331          0.987687 -0.052607      0.999928\n",
       "   33 -0.009964          0.989481 -0.054209      0.999881\n",
       "   34 -0.009810          0.990418 -0.055923      0.999878\n",
       "   35 -0.009764          0.990070 -0.057584      0.999908\n",
       "   36 -0.012980          0.989989 -0.059265      0.999943\n",
       "   37 -0.014624          0.990177 -0.060889      0.999923,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.126164          0.971199  0.270105      0.955405\n",
       "   1   0.157012          0.941569  0.089852      0.977774\n",
       "   2   0.050192          0.984904  0.057562      0.984017\n",
       "   3   0.044312          0.986215  0.039930      0.987476\n",
       "   4   0.033161          0.988437  0.028955      0.989803\n",
       "   5   0.027417          0.988571  0.020799      0.991061\n",
       "   6   0.021914          0.989936  0.014032      0.992476\n",
       "   7   0.023116          0.988972  0.008399      0.993832\n",
       "   8   0.019272          0.990016  0.003668      0.994762\n",
       "   9   0.016218          0.990471 -0.000627      0.995739\n",
       "   10  0.013931          0.990685 -0.004565      0.996374\n",
       "   11  0.012418          0.990230 -0.007839      0.997050\n",
       "   12  0.011147          0.989855 -0.010828      0.997524\n",
       "   13  0.009734          0.990310 -0.013608      0.998004\n",
       "   14  0.008310          0.989561 -0.016252      0.998424\n",
       "   15  0.010681          0.990310 -0.018685      0.998763\n",
       "   16  0.008904          0.988490 -0.020633      0.998650\n",
       "   17  0.011385          0.989748 -0.022805      0.999061\n",
       "   18  0.006630          0.989668 -0.024904      0.999279\n",
       "   19  0.005769          0.990471 -0.026682      0.999324\n",
       "   20  0.005998          0.989855 -0.028789      0.999499\n",
       "   21  0.004259          0.990712 -0.030540      0.999568\n",
       "   22  0.002893          0.989936 -0.032268      0.999538\n",
       "   23 -0.000020          0.989802 -0.034141      0.999690\n",
       "   24  0.000590          0.989267 -0.035914      0.999771\n",
       "   25  0.002242          0.990150 -0.037592      0.999762\n",
       "   26 -0.000849          0.989534 -0.039307      0.999800\n",
       "   27 -0.000492          0.989293 -0.041020      0.999815\n",
       "   28 -0.002090          0.990337 -0.042693      0.999836\n",
       "   29 -0.005705          0.990471 -0.044367      0.999854\n",
       "   30 -0.005969          0.990846 -0.046089      0.999902\n",
       "   31 -0.005477          0.990551 -0.047687      0.999872\n",
       "   32 -0.009425          0.990096 -0.049391      0.999851\n",
       "   33 -0.007833          0.990498 -0.051059      0.999881\n",
       "   34 -0.004750          0.989534 -0.052708      0.999860\n",
       "   35 -0.009926          0.990525 -0.054374      0.999887\n",
       "   36 -0.010451          0.990203 -0.056062      0.999952\n",
       "   37 -0.013068          0.989695 -0.057728      0.999931\n",
       "   38 -0.014596          0.989936 -0.059349      0.999943\n",
       "   39 -0.014489          0.990337 -0.061048      0.999970\n",
       "   40 -0.019596          0.989481 -0.062679      0.999943\n",
       "   41 -0.016932          0.988464 -0.064256      0.999934\n",
       "   42 -0.022272          0.990873 -0.065938      0.999940\n",
       "   43 -0.022219          0.990096 -0.067636      0.999943\n",
       "   44 -0.020904          0.990337 -0.069220      0.999878\n",
       "   45 -0.023764          0.990016 -0.070889      0.999946\n",
       "   46 -0.021256          0.990578 -0.072539      0.999940\n",
       "   47 -0.025469          0.990926 -0.074182      0.999949\n",
       "   48 -0.025097          0.990391 -0.075835      0.999955\n",
       "   49 -0.024033          0.990310 -0.077470      0.999943\n",
       "   50 -0.029541          0.989855 -0.079150      0.999976]),\n",
       " ({'use_char': True,\n",
       "   'crf': True,\n",
       "   'use_pos': True,\n",
       "   'embedding_matrix': 'fastext',\n",
       "   'trainable': True,\n",
       "   'embed_dim': 300,\n",
       "   'use_morpheme': True,\n",
       "   'use_word': False,\n",
       "   'input_dropout': False,\n",
       "   'stack_lstm': 1,\n",
       "   'epochs': 100,\n",
       "   'early_stopping': True,\n",
       "   'patience': 20,\n",
       "   'min_delta': 0.0001,\n",
       "   'stack_cross': False,\n",
       "   'stack_double': False,\n",
       "   'rec_dropout': 0.1},\n",
       "  [(84.09689310163245, 84.31890179514255, 84.2077511204851),\n",
       "   (83.13577586206897, 80.91242789722077, 82.00903534414032),\n",
       "   (84.26966292134831, 83.12342569269522, 83.69261983261477)],\n",
       "  [    val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.107388          0.976713  0.280391      0.945787\n",
       "   1   0.062628          0.983458  0.084417      0.979192\n",
       "   2   0.050969          0.984904  0.053001      0.984923\n",
       "   3   0.039451          0.986911  0.036325      0.988141\n",
       "   4   0.031360          0.988838  0.025380      0.990221\n",
       "   5   0.030078          0.986777  0.017965      0.991606\n",
       "   6   0.034819          0.982441  0.011556      0.992780\n",
       "   7   0.020292          0.989534  0.006333      0.993838\n",
       "   8   0.017056          0.990926  0.001470      0.994645\n",
       "   9   0.019252          0.988785 -0.002838      0.995840\n",
       "   10  0.015744          0.988865 -0.006266      0.996338\n",
       "   11  0.010614          0.990230 -0.009616      0.997107\n",
       "   12  0.011107          0.991328 -0.012490      0.997434\n",
       "   13  0.009350          0.990471 -0.015200      0.998007\n",
       "   14  0.008069          0.990257 -0.017653      0.998239\n",
       "   15  0.009030          0.989320 -0.020350      0.998835\n",
       "   16  0.008594          0.990685 -0.022572      0.998996\n",
       "   17  0.008673          0.991247 -0.024545      0.999157\n",
       "   18  0.008205          0.991033 -0.026716      0.999380\n",
       "   19  0.006531          0.989802 -0.028442      0.999362\n",
       "   20  0.004967          0.989855 -0.030367      0.999538\n",
       "   21  0.006796          0.991113 -0.032109      0.999577\n",
       "   22  0.003844          0.991033 -0.033912      0.999601\n",
       "   23  0.003414          0.990525 -0.035750      0.999705\n",
       "   24  0.000929          0.990391 -0.037447      0.999699\n",
       "   25  0.001367          0.991328 -0.039256      0.999782\n",
       "   26  0.001019          0.990632 -0.040883      0.999833\n",
       "   27  0.002516          0.991461 -0.042605      0.999803\n",
       "   28  0.001417          0.991113 -0.044376      0.999920\n",
       "   29 -0.000114          0.990792 -0.045967      0.999890\n",
       "   30 -0.000430          0.991247 -0.047666      0.999857\n",
       "   31 -0.003956          0.990846 -0.049282      0.999854\n",
       "   32 -0.003672          0.990551 -0.050999      0.999914\n",
       "   33 -0.000473          0.991381 -0.052630      0.999902\n",
       "   34  0.000133          0.990980 -0.054382      0.999964\n",
       "   35 -0.005268          0.991033 -0.055974      0.999905\n",
       "   36 -0.006304          0.990257 -0.057669      0.999955\n",
       "   37 -0.008310          0.991060 -0.059308      0.999970\n",
       "   38 -0.006884          0.990739 -0.060922      0.999934\n",
       "   39 -0.010061          0.990658 -0.062509      0.999949\n",
       "   40 -0.010286          0.990739 -0.064215      0.999934\n",
       "   41 -0.011078          0.991087 -0.065843      0.999917\n",
       "   42 -0.015549          0.990418 -0.067536      0.999964\n",
       "   43 -0.014705          0.990980 -0.069191      0.999961\n",
       "   44 -0.016868          0.991194 -0.070834      0.999955\n",
       "   45 -0.018363          0.990230 -0.072479      0.999952\n",
       "   46 -0.018768          0.990712 -0.074075      0.999946\n",
       "   47 -0.019093          0.990980 -0.075798      0.999973,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.107135          0.972698  0.288607      0.948707\n",
       "   1   0.066086          0.982495  0.082190      0.979535\n",
       "   2   0.041157          0.985439  0.050299      0.985033\n",
       "   3   0.027472          0.988303  0.031840      0.988242\n",
       "   4   0.024646          0.987875  0.020958      0.989905\n",
       "   5   0.015789          0.989641  0.012497      0.991576\n",
       "   6   0.014552          0.988490  0.006016      0.992905\n",
       "   7   0.009938          0.989989  0.000584      0.993963\n",
       "   8   0.007101          0.990418 -0.004383      0.995095\n",
       "   9   0.009656          0.989802 -0.008500      0.995858\n",
       "   10  0.003611          0.991087 -0.012192      0.996460\n",
       "   11  0.011252          0.990418 -0.015510      0.997050\n",
       "   12  0.001393          0.991328 -0.018241      0.997679\n",
       "   13  0.001273          0.991033 -0.021241      0.998027\n",
       "   14  0.006754          0.988249 -0.023643      0.998519\n",
       "   15  0.002892          0.990418 -0.025976      0.998790\n",
       "   16 -0.004204          0.990498 -0.027990      0.998835\n",
       "   17 -0.002737          0.990926 -0.030185      0.999154\n",
       "   18 -0.005587          0.990953 -0.032220      0.999395\n",
       "   19 -0.007104          0.990739 -0.034003      0.999416\n",
       "   20 -0.005906          0.990337 -0.036061      0.999583\n",
       "   21 -0.006161          0.989507 -0.037736      0.999568\n",
       "   22 -0.010571          0.991435 -0.039604      0.999702\n",
       "   23 -0.011220          0.991354 -0.041257      0.999592\n",
       "   24 -0.012111          0.990016 -0.043076      0.999759\n",
       "   25 -0.010908          0.991595 -0.044772      0.999782\n",
       "   26 -0.013099          0.990899 -0.046585      0.999836\n",
       "   27 -0.011823          0.990498 -0.048157      0.999800\n",
       "   28 -0.009046          0.991301 -0.049921      0.999878\n",
       "   29 -0.015184          0.991569 -0.051547      0.999830\n",
       "   30 -0.015135          0.989374 -0.053158      0.999872\n",
       "   31 -0.019214          0.991274 -0.054893      0.999899\n",
       "   32 -0.020975          0.991354 -0.056584      0.999908\n",
       "   33 -0.020596          0.991167 -0.058216      0.999875\n",
       "   34 -0.020430          0.991569 -0.059853      0.999890\n",
       "   35 -0.022435          0.991006 -0.061556      0.999911\n",
       "   36 -0.023623          0.991488 -0.063213      0.999940\n",
       "   37 -0.024526          0.991301 -0.064877      0.999943\n",
       "   38 -0.026170          0.991328 -0.066522      0.999955\n",
       "   39 -0.026068          0.990792 -0.068187      0.999940\n",
       "   40 -0.026899          0.990043 -0.069752      0.999914\n",
       "   41 -0.027929          0.991328 -0.071457      0.999931\n",
       "   42 -0.028118          0.991595 -0.073072      0.999943\n",
       "   43 -0.033811          0.991194 -0.074807      0.999970\n",
       "   44 -0.033598          0.990658 -0.076345      0.999920\n",
       "   45 -0.032750          0.990926 -0.078066      0.999973,\n",
       "       val_loss  val_crf_accuracy      loss  crf_accuracy\n",
       "   0   0.102640          0.973555  0.282031      0.945805\n",
       "   1   0.058748          0.983378  0.080289      0.979422\n",
       "   2   0.039441          0.986242  0.047775      0.985262\n",
       "   3   0.037923          0.985867  0.032295      0.988415\n",
       "   4   0.023053          0.989106  0.022432      0.990310\n",
       "   5   0.021362          0.989722  0.014725      0.991722\n",
       "   6   0.014187          0.990418  0.008484      0.993072\n",
       "   7   0.014188          0.988758  0.003523      0.994049\n",
       "   8   0.011034          0.991569 -0.001587      0.995176\n",
       "   9   0.008954          0.992104 -0.005196      0.995769\n",
       "   10  0.005523          0.991461 -0.008716      0.996558\n",
       "   11  0.006784          0.989963 -0.012294      0.997309\n",
       "   12  0.006117          0.989882 -0.015056      0.997643\n",
       "   13  0.001188          0.991836 -0.017755      0.998105\n",
       "   14  0.000794          0.991033 -0.020335      0.998570\n",
       "   15  0.001899          0.991113 -0.022479      0.998680\n",
       "   16 -0.000524          0.991622 -0.024841      0.999044\n",
       "   17 -0.001689          0.991087 -0.026931      0.999169\n",
       "   18  0.000909          0.991301 -0.028984      0.999485\n",
       "   19 -0.001043          0.991676 -0.030792      0.999458\n",
       "   20 -0.003988          0.991354 -0.032672      0.999493\n",
       "   21 -0.005283          0.991890 -0.034349      0.999490\n",
       "   22 -0.005673          0.991461 -0.036220      0.999660\n",
       "   23 -0.005678          0.991060 -0.037967      0.999636\n",
       "   24 -0.007351          0.990471 -0.039858      0.999788\n",
       "   25 -0.006644          0.991087 -0.041604      0.999845\n",
       "   26 -0.008843          0.991676 -0.043213      0.999851\n",
       "   27 -0.010347          0.991140 -0.044830      0.999800\n",
       "   28 -0.012467          0.990819 -0.046555      0.999827\n",
       "   29 -0.013480          0.990953 -0.048229      0.999857])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(configs, results, histories))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open('treebank_results_1.pkl', 'wb') as f:\n",
    "    pickle.dump(list(zip(configs, results, histories)), f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open('treebank_results_2_test25.pkl', 'wb') as f:\n",
    "    pickle.dump(list(zip(configs, results, preds, histories)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(configs, results):\n",
    "    dict_res = []\n",
    "    for conf, res in zip(configs, results):\n",
    "        dr = {}\n",
    "        for i, r in enumerate(res):\n",
    "            split_name = chr(ord('a')+i)\n",
    "            dr['prec_'+split_name], dr['recall_'+split_name], dr['f1_'+split_name] = r\n",
    "        dr.update(conf)\n",
    "        dict_res.append(dr)\n",
    "    rdf = (pd.DataFrame(dict_res)\n",
    "           .assign(prec = lambda x: (x.prec_a + x.prec_b + x.prec_c)/3)\n",
    "           .assign(recall = lambda x: (x.recall_a + x.recall_b + x.recall_c)/3)\n",
    "           .assign(f1 = lambda x: (x.f1_a + x.f1_b + x.f1_c)/3))\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = pickle.load(open('treebank_results_1.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = pickle.load(open('treebank_results_2_test25.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf1 = get_results_df([c for c, r, h in res1], [r for c, r, h in res1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf2 = get_results_df([c for c, r, p, h in res2], [r for c, r, p, h in res2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crf</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>embed_dim</th>\n",
       "      <th>embedding_matrix</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1_a</th>\n",
       "      <th>f1_b</th>\n",
       "      <th>f1_c</th>\n",
       "      <th>input_dropout</th>\n",
       "      <th>min_delta</th>\n",
       "      <th>...</th>\n",
       "      <th>stack_double</th>\n",
       "      <th>stack_lstm</th>\n",
       "      <th>trainable</th>\n",
       "      <th>use_char</th>\n",
       "      <th>use_morpheme</th>\n",
       "      <th>use_pos</th>\n",
       "      <th>use_word</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>61.595231</td>\n",
       "      <td>64.524986</td>\n",
       "      <td>63.937419</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>66.866298</td>\n",
       "      <td>60.221498</td>\n",
       "      <td>63.352545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>72.074967</td>\n",
       "      <td>71.615721</td>\n",
       "      <td>72.101911</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>73.574440</td>\n",
       "      <td>70.383441</td>\n",
       "      <td>71.930866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>fastext</td>\n",
       "      <td>100</td>\n",
       "      <td>77.924131</td>\n",
       "      <td>76.407437</td>\n",
       "      <td>77.421053</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>78.371539</td>\n",
       "      <td>76.234033</td>\n",
       "      <td>77.250873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>fastext</td>\n",
       "      <td>100</td>\n",
       "      <td>80.941052</td>\n",
       "      <td>79.862215</td>\n",
       "      <td>80.050761</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>80.810288</td>\n",
       "      <td>79.768234</td>\n",
       "      <td>80.284676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>69.732492</td>\n",
       "      <td>67.697498</td>\n",
       "      <td>70.299037</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>74.882658</td>\n",
       "      <td>64.751970</td>\n",
       "      <td>69.243009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    crf  early_stopping  embed_dim embedding_matrix  epochs       f1_a  \\\n",
       "0  True            True         70             None     100  61.595231   \n",
       "1  True            True         70             None     100  72.074967   \n",
       "2  True            True        300          fastext     100  77.924131   \n",
       "3  True            True        300          fastext     100  80.941052   \n",
       "4  True            True         70             None     100  69.732492   \n",
       "\n",
       "        f1_b       f1_c  input_dropout  min_delta  ...  stack_double  \\\n",
       "0  64.524986  63.937419          False     0.0001  ...         False   \n",
       "1  71.615721  72.101911          False     0.0001  ...         False   \n",
       "2  76.407437  77.421053          False     0.0001  ...         False   \n",
       "3  79.862215  80.050761          False     0.0001  ...         False   \n",
       "4  67.697498  70.299037          False     0.0001  ...         False   \n",
       "\n",
       "   stack_lstm  trainable  use_char  use_morpheme  use_pos  use_word  \\\n",
       "0           1       True     False          True    False     False   \n",
       "1           1       True     False          True     True     False   \n",
       "2           1       True     False          True    False     False   \n",
       "3           1       True     False          True     True     False   \n",
       "4           1       True      True          True    False     False   \n",
       "\n",
       "        prec     recall         f1  \n",
       "0  66.866298  60.221498  63.352545  \n",
       "1  73.574440  70.383441  71.930866  \n",
       "2  78.371539  76.234033  77.250873  \n",
       "3  80.810288  79.768234  80.284676  \n",
       "4  74.882658  64.751970  69.243009  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>use_char</th>\n",
       "      <th colspan=\"2\" halign=\"left\">False</th>\n",
       "      <th colspan=\"2\" halign=\"left\">True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_pos</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embedding_matrix</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>63.4</td>\n",
       "      <td>71.9</td>\n",
       "      <td>69.2</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastext</th>\n",
       "      <td>77.3</td>\n",
       "      <td>80.3</td>\n",
       "      <td>82.0</td>\n",
       "      <td>83.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "use_char         False       True       \n",
       "use_pos          False True  False True \n",
       "embedding_matrix                        \n",
       "No                63.4  71.9  69.2  75.0\n",
       "fastext           77.3  80.3  82.0  83.3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (rdf2.fillna('No')\n",
    " .groupby(['use_char', 'use_pos', 'embedding_matrix'])\n",
    " .apply(lambda x: x.f1.mean())\n",
    " .unstack(level=[0,1])\n",
    " .round(1)\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>use_char</th>\n",
       "      <th colspan=\"2\" halign=\"left\">False</th>\n",
       "      <th colspan=\"2\" halign=\"left\">True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_pos</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embedding_matrix</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>67.9</td>\n",
       "      <td>74.4</td>\n",
       "      <td>70.7</td>\n",
       "      <td>75.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastext</th>\n",
       "      <td>79.4</td>\n",
       "      <td>83.4</td>\n",
       "      <td>82.9</td>\n",
       "      <td>84.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "use_char         False       True       \n",
       "use_pos          False True  False True \n",
       "embedding_matrix                        \n",
       "No                67.9  74.4  70.7  75.8\n",
       "fastext           79.4  83.4  82.9  84.6"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (rdf1.fillna('No')\n",
    " .groupby(['use_char', 'use_pos', 'embedding_matrix'])\n",
    " .apply(lambda x: x.f1.mean())\n",
    " .unstack(level=[0,1])\n",
    " .round(1)\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
