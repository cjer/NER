{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T12:26:06.209424Z",
     "start_time": "2019-02-07T12:25:47.401352Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "d5nJycQ6Nsao",
    "outputId": "9a2521ed-f067-49a3-ae47-e9480a1d35f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T12:26:06.553091Z",
     "start_time": "2019-02-07T12:26:06.209424Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "QkpbqANBPFDL"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('joint_corpus_with_pos_gazet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T12:26:06.631197Z",
     "start_time": "2019-02-07T12:26:06.553091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>WORD</th>\n",
       "      <th>orig_form</th>\n",
       "      <th>POS_CONC</th>\n",
       "      <th>NER</th>\n",
       "      <th>corpus_form</th>\n",
       "      <th>is_in_gazet_loc</th>\n",
       "      <th>is_in_gazet_org</th>\n",
       "      <th>is_in_gazet_per</th>\n",
       "      <th>is_in_gazet_loc_fuzzy</th>\n",
       "      <th>is_in_gazet_org_fuzzy</th>\n",
       "      <th>is_in_gazet_per_fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>נראה</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "      <td>נראה</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>שאביטל</td>\n",
       "      <td>REL|NNP</td>\n",
       "      <td>I_PERS</td>\n",
       "      <td>שאביטל</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>אברג'יל</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I_PERS</td>\n",
       "      <td>אברג'יל</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>(</td>\n",
       "      <td>yyLRB</td>\n",
       "      <td>O</td>\n",
       "      <td>(</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לשעבר</td>\n",
       "      <td>RB</td>\n",
       "      <td>O</td>\n",
       "      <td>לשעבר</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent  WORD orig_form POS_CONC     NER corpus_form  is_in_gazet_loc  \\\n",
       "0     1     1      נראה       VB       O        נראה            False   \n",
       "1     1     2    שאביטל  REL|NNP  I_PERS      שאביטל            False   \n",
       "2     1     3   אברג'יל      NNP  I_PERS     אברג'יל            False   \n",
       "3     1     4         (    yyLRB       O           (            False   \n",
       "4     1     5     לשעבר       RB       O       לשעבר            False   \n",
       "\n",
       "   is_in_gazet_org  is_in_gazet_per  is_in_gazet_loc_fuzzy  \\\n",
       "0            False            False                  False   \n",
       "1            False            False                  False   \n",
       "2            False            False                  False   \n",
       "3            False            False                  False   \n",
       "4            False            False                  False   \n",
       "\n",
       "   is_in_gazet_org_fuzzy  is_in_gazet_per_fuzzy  \n",
       "0                  False                  False  \n",
       "1                  False                   True  \n",
       "2                  False                   True  \n",
       "3                  False                  False  \n",
       "4                  False                  False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dOl0ioZ5P-ql"
   },
   "source": [
    "Now, as bert expect sequences, let's create a sentence getter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T12:26:06.803034Z",
     "start_time": "2019-02-07T12:26:06.631197Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TG2Jd3vQQOVh"
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "\n",
    "    def __init__(self, data, max_sent=None):\n",
    "        self.index = 0\n",
    "        self.max_sent = max_sent\n",
    "        self.tokens = data[\"corpus_form\"]\n",
    "        self.labels = data[\"NER\"]\n",
    "\n",
    "    def sentences(self):\n",
    "        sent = []\n",
    "        counter = 0\n",
    "\n",
    "        for token, label in zip(self.tokens, self.labels):\n",
    "            if token == \"DOCSTART\":\n",
    "                continue\n",
    "            sent.append((token, label))\n",
    "            if token.strip() == \".\":\n",
    "                yield sent\n",
    "                sent = []\n",
    "                counter += 1\n",
    "            if self.max_sent is not None and counter >= self.max_sent:\n",
    "                return\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            while True:\n",
    "                sent = []\n",
    "                next_token = self.tokens[self.index]\n",
    "                if next_token == \"DOCSTART\":\n",
    "                    continue\n",
    "                next_label = self.labels[self.index]\n",
    "                sent.append((next_token, next_label))\n",
    "                self.index += 1\n",
    "                if next_token.strip() == \".\":\n",
    "                    return sent\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YKLqvAPQYwR"
   },
   "source": [
    "Let's check our deep learning libraries are working properley:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T12:26:06.849896Z",
     "start_time": "2019-02-07T12:26:06.803034Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9zPDZdLEQe6y",
    "outputId": "6f668d86-318c-4b8a-aa40-595649dae2b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Number of gpus: 4\n",
      "Name of gpu: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "print(\"Device: \" + str(device))\n",
    "print(\"Number of gpus: \" + str(n_gpu))\n",
    "print(\"Name of gpu: \" + torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AWq2gJwOTDoO"
   },
   "source": [
    "We'll also add some constants that will determine the maximum sequence length and maximum batch sizes that we will feed the gpu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T12:26:06.881139Z",
     "start_time": "2019-02-07T12:26:06.849896Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "w-dm7-rWTJ4Q"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 75\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-EDusFH_RGlT"
   },
   "source": [
    "Next, let's get all of our sentences and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T12:26:07.021733Z",
     "start_time": "2019-02-07T12:26:06.881139Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "AWCUKWd8RLho",
    "outputId": "14322126-e747-452e-f359-2a2c5430b104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['נראה', 'שאביטל', \"אברג'יל\", '(', 'לשעבר', 'אוז', ')', ',', 'אוהבת', 'לא', 'רק', 'לשחק', 'אצל', 'דן', \"תורג'מן\", '(', 'בסרט', '\"', 'משהו', 'מתוק', '\"', ')', ',', 'אלא', 'גם', 'איתו', '.']\n",
      "['O', 'I_PERS', 'I_PERS', 'O', 'O', 'I_PERS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I_PERS', 'I_PERS', 'O', 'O', 'O', 'I_MISC__ENT', 'I_MISC__ENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "all_sentences = [[token for token, label in sent] for sent in getter.sentences()]\n",
    "all_orig_labels = [[label for token, label in sent] for sent in getter.sentences()]\n",
    "\n",
    "print(all_sentences[0])\n",
    "print(all_orig_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FQJAVeO2RdwO"
   },
   "source": [
    "Moving forward, we'll want to split our dataset into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T12:26:07.037361Z",
     "start_time": "2019-02-07T12:26:07.021733Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BRSLS-SIRhsa"
   },
   "outputs": [],
   "source": [
    "train_sentences, test_sentences, train_orig_labels, test_orig_labels = train_test_split(all_sentences, all_orig_labels, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "32FCg00MRuoJ"
   },
   "source": [
    "As bert expects a tokenized sentence, we'll need to use the BertTokenizer with multilingual support. We'll create a function to achieve this. It's important to note that bert tend to split words, or as they call it, split into word pieces. Therefore, we'll need to update our labels arrays and expend them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T12:26:09.364929Z",
     "start_time": "2019-02-07T12:26:07.037361Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "hxeQKHIsSTVM",
    "outputId": "33175f19-6dd3-426c-a2ce-f9cb8d50d50f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ל', '##ר', '##פ', '##פורט', 'לא', 'היה', 'מ', '##עולם', 'קשר', 'לי', '##הו', '##דים', 'או', 'לישראל', '.']\n",
      "['I_PERS', 'I_PERS', 'I_PERS', 'I_PERS', 'O', 'O', 'O', 'O', 'O', 'I_MISC__AFF', 'I_MISC__AFF', 'I_MISC__AFF', 'O', 'I_LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "\n",
    "def tokenize(sentences, orig_labels):\n",
    "    tokenized_texts = []\n",
    "    labels = []\n",
    "    for sent, sent_labels in zip(sentences, orig_labels):\n",
    "        bert_tokens = []\n",
    "        bert_labels = []\n",
    "        for orig_token, orig_label in zip(sent, sent_labels):\n",
    "            b_tokens = tokenizer.tokenize(orig_token)\n",
    "            bert_tokens.extend(b_tokens)\n",
    "            for b_token in b_tokens:\n",
    "                bert_labels.append(orig_label)\n",
    "        tokenized_texts.append(bert_tokens)\n",
    "        labels.append(bert_labels)\n",
    "\n",
    "        assert len(bert_tokens) == len(bert_labels)\n",
    "\n",
    "    return tokenized_texts, labels\n",
    "\n",
    "\n",
    "train_tokenized_texts, train_labels = tokenize(train_sentences, train_orig_labels)\n",
    "print(train_tokenized_texts[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uBzeYGHgSZ7r"
   },
   "source": [
    "Next we need to create sequences with padding to give to bert. We'll add first some utilties to convert labels into numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T12:26:09.380601Z",
     "start_time": "2019-02-07T12:26:09.364929Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "G1NcAaFbSnmF"
   },
   "outputs": [],
   "source": [
    "tags_vals = list(set(data[\"NER\"].values))\n",
    "tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
    "idx2tag = {i: t for i, t in enumerate(tags_vals)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-H79vf2hS0vs"
   },
   "source": [
    "Now, we can convert our sentences and labels into sequences with paddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T12:26:09.692976Z",
     "start_time": "2019-02-07T12:26:09.380601Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "f04k8SLBS-A-"
   },
   "outputs": [],
   "source": [
    "def pad_sentences_and_labels(tokenized_texts, labels):\n",
    "    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                              maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                         maxlen=MAX_LEN, value=tag2idx[\"O\"], padding=\"post\",\n",
    "                         dtype=\"long\", truncating=\"post\")\n",
    "\n",
    "    attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\n",
    "    \n",
    "    return input_ids, tags, attention_masks\n",
    "  \n",
    "\n",
    "input_ids, tags, attention_masks = pad_sentences_and_labels(train_tokenized_texts, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SrXDvmUrTkWN"
   },
   "source": [
    "We're almost done. All that is left is to make tensors and  data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T12:26:09.724220Z",
     "start_time": "2019-02-07T12:26:09.692976Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "iGy-clNDTx_w"
   },
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(input_ids, dtype=torch.long)\n",
    "tr_tags = torch.tensor(tags, dtype=torch.long)\n",
    "tr_masks = torch.tensor(attention_masks, dtype=torch.long)\n",
    "\n",
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_-uNK49T1ay"
   },
   "source": [
    "Now we're ready to create our bert model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T16:53:17.984380Z",
     "start_time": "2019-02-07T12:26:09.724220Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1751
    },
    "colab_type": "code",
    "id": "BCocK1v0T7fK",
    "outputId": "63e16daa-f854-46d3-9fbd-5ce5ac3d71d8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 1/5 [00:23<01:32, 23.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.37259750548554094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 2/5 [00:46<01:09, 23.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10909128620436317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 3/5 [01:10<00:46, 23.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.06594536041742877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 4/5 [01:34<00:23, 23.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04130892623460999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [01:58<00:00, 23.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.026234773520723377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-multilingual-uncased\", num_labels=len(tag2idx))\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\n",
    "\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss / nb_tr_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-RLt0brUNvh"
   },
   "source": [
    "Great, we now have a trained model. Let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:25:35.868708Z",
     "start_time": "2019-02-08T07:25:17.222530Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "AJsv0lndURWz",
    "outputId": "f9941a24-7635-4b1c-85c8-3c82134187c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.08596838836092502\n",
      "Validation Accuracy: 0.9820673076923079\n",
      "F1-Score: 0.7622478386167146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/dan/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def test_model():\n",
    "  classes_without_O = [x.replace('_', '-') for x in data[\"NER\"].tolist() if x!='O']\n",
    "      \n",
    "  test_tokenized_texts, test_labels = tokenize(test_sentences, test_orig_labels)\n",
    "  input_ids, tags, attention_masks = pad_sentences_and_labels(test_tokenized_texts, test_labels)\n",
    "\n",
    "  val_inputs = torch.tensor(input_ids, dtype=torch.long)\n",
    "  val_tags = torch.tensor(tags, dtype=torch.long)\n",
    "  val_masks = torch.tensor(attention_masks, dtype=torch.long)\n",
    "\n",
    "  test_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "  test_sampler = SequentialSampler(test_data)\n",
    "  test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=bs)\n",
    "\n",
    "  model.eval()\n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "  predictions, true_labels = [], []\n",
    "  counter = 0\n",
    "  for batch in test_dataloader:\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "      b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "      with torch.no_grad():\n",
    "          tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                                attention_mask=b_input_mask, labels=b_labels)\n",
    "          logits = model(b_input_ids, token_type_ids=None,\n",
    "                         attention_mask=b_input_mask)\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = b_labels.to('cpu').numpy()\n",
    "      predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "      true_labels.append(label_ids)\n",
    "\n",
    "      tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "      eval_loss += tmp_eval_loss.mean().item()\n",
    "      eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "      nb_eval_examples += b_input_ids.size(0)\n",
    "      nb_eval_steps += 1\n",
    "  eval_loss = eval_loss / nb_eval_steps\n",
    "  print(\"Validation loss: {}\".format(eval_loss))\n",
    "  print(\"Validation Accuracy: {}\".format(eval_accuracy / nb_eval_steps))\n",
    "  pred_tags = [tags_vals[p_i].replace('_', '-') for p in predictions for p_i in p]\n",
    "  test_tags = [tags_vals[l_ii].replace('_', '-') for l in true_labels for l_i in l for l_ii in l_i]\n",
    "  print(\"F1-Score: {}\".format(f1_score(pred_tags, test_tags)))\n",
    "\n",
    "  y_true = pd.Series(test_tags)\n",
    "  y_pred = pd.Series(pred_tags)\n",
    "  cross_tab = pd.crosstab(y_true, y_pred, rownames=['Real Label'], colnames=['Prediction'], margins=True)\n",
    "  report = classification_report(y_true, y_pred, labels=classes_without_O, target_names=classes_without_O)\n",
    "  report_with_O = classification_report(y_true, y_pred)\n",
    "\n",
    "  return cross_tab, report, report_with_O, y_true, y_pred\n",
    "\n",
    "#     print(test_tokenized_texts[0])\n",
    "#     print([idx2tag.get(i) for i in predictions[0]])\n",
    "#     print([idx2tag.get(i) for i in true_labels[0][0]])\n",
    "    \n",
    "\n",
    "cross_tab, report, report_with_O, y_true, y_pred = test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T06:13:14.174658Z",
     "start_time": "2019-02-07T23:58:18.060997Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▎        | 1/8 [00:23<02:45, 23.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.020349489990621805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 2/8 [00:47<02:21, 23.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.014265910281162513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|███▊      | 3/8 [01:10<01:58, 23.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.012433759858954306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 4/8 [01:34<01:34, 23.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.010185604933404216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|██████▎   | 5/8 [01:58<01:10, 23.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.008413136302567037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 6/8 [02:21<00:47, 23.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.007044485827607691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  88%|████████▊ | 7/8 [02:45<00:23, 23.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.005511880198977643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 8/8 [03:09<00:00, 23.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.005124702012644296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 8\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss / nb_tr_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:33:29.863948Z",
     "start_time": "2019-02-08T07:25:41.635360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.08489784598350525\n",
      "Validation Accuracy: 0.9842735042735045\n",
      "F1-Score: 0.8152327221438646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/dan/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "cross_tab, report, report_with_O, y_true, y_pred = test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:33:30.110821Z",
     "start_time": "2019-02-08T07:33:29.863948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 60225 tokens with 1415 phrases; found: 1421 phrases; correct: 1156.\n",
      "accuracy:  87.88%; (non-O)\n",
      "accuracy:  98.45%; precision:  81.35%; recall:  81.70%; FB1:  81.52\n",
      "             DATE: precision:  66.99%; recall:  64.49%; FB1:  65.71  103\n",
      "              LOC: precision:  86.02%; recall:  85.50%; FB1:  85.76  329\n",
      "        MISC--AFF: precision:  90.96%; recall:  91.94%; FB1:  91.44  188\n",
      "        MISC--ENT: precision:  70.59%; recall:  54.55%; FB1:  61.54  17\n",
      "       MISC-EVENT: precision:  72.22%; recall:  81.25%; FB1:  76.47  18\n",
      "            MONEY: precision: 100.00%; recall:  95.56%; FB1:  97.73  43\n",
      "              ORG: precision:  64.89%; recall:  69.06%; FB1:  66.91  282\n",
      "          PERCENT: precision:  93.55%; recall:  95.08%; FB1:  94.31  62\n",
      "             PERS: precision:  85.95%; recall:  85.48%; FB1:  85.71  370\n",
      "             TIME: precision:  66.67%; recall:  60.00%; FB1:  63.16  9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(81.35116115411682, 81.69611307420494, 81.52327221438645)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from conlleval import evaluate\n",
    "evaluate(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Phase3_DL.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
